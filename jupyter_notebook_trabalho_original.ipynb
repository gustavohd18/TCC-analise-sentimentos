{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook da Integradora 4\n",
    "## Aluno: Thiago Medina\n",
    "## Orientadora: Isabel H. Manssour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, os imports necessário para a realização de todo o notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "#1\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install unidecode\n",
    "!{sys.executable} -m pip install tweepy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install ssl\n",
    "\n",
    "import ssl\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: regex in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: click in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: unidecode in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tweepy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: xlrd in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ssl\n",
      "  Using cached ssl-1.16.tar.gz (33 kB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[31m    ERROR: Command errored out with exit status 1:\r\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-pip-egg-info-csvejgj8\r\n",
      "         cwd: /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/\r\n",
      "    Complete output (6 lines):\r\n",
      "    Traceback (most recent call last):\r\n",
      "      File \"<string>\", line 1, in <module>\r\n",
      "      File \"/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py\", line 33\r\n",
      "        print 'looking for', f\r\n",
      "              ^\r\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('looking for', f)?\r\n",
      "    ----------------------------------------\u001b[0m\r\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## O trabalho todo está separado em 3 partes:\n",
    "### 1- Coleta dos tweets\n",
    "### 2- Pré-processamento dos tweets.\n",
    "### 3- Treinamento e teste por parte do algoritmo\n",
    "\n",
    "Iniciamos com a coleta dos tweets:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Necessário possuir suas chaves próprias para a coleta de tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "#2\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "#3\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "public_tweets = api.home_timeline()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query para a coleta de tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Altere a query de pesquisa (pode-se utilizar operadores lógicos). Altere também a quantidade de tweets que deseja coletar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "#4\n",
    "#query = '(#masterchef)  OR(#MasterChefBR) OR (#masterchefbrasil)  -filter:retweets'\n",
    "#query = '(#bbb21) -filter:retweets'\n",
    "query = '(#covid19) OR (#covid) OR (#coronavirus) -filter:retweets'\n",
    "#query = '(#educacao AND (-@mpsnet AND -@mpsnet2)) -filter:retweets'\n",
    "\n",
    "cursor_tweets = tw.Cursor(api.search,\n",
    "            q=query,lang = 'pt',tweet_mode='extended').items(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos apenas a coluna com o texto dos tweets e a data de criação dos mesmos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "#5\n",
    "tweets_dict = {}\n",
    "tweets_dict = tweets_dict.fromkeys(['created_at', 'full_text'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "#6\n",
    "for tweet in cursor_tweets:\n",
    "    for key in tweets_dict.keys():\n",
    "        try:\n",
    "            twvalue = tweet._json[key]\n",
    "            tweets_dict[key].append(twvalue)\n",
    "        except KeyError:\n",
    "            twvalue = \"\"\n",
    "            if(tweets_dict[key] is None):\n",
    "                tweets_dict[key] = [twvalue]\n",
    "            else:\n",
    "                tweets_dict[key].append(twvalue)\n",
    "        except:\n",
    "            tweets_dict[key] = [twvalue]\n",
    "        #print(\"tweets_dict[key]: {} - tweet[key]: {}\".format(tweets_dict[key],  twvalue))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, listamos os tweets coletados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "#7\n",
    "tweets_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'created_at': ['Sun Aug 01 17:49:32 +0000 2021'],\n",
       " 'full_text': ['Sociedade\\nHá mais 28 mortes e 1.513 infecções por Coronavírus no país\\n#covid19 #mocambique \\nhttps://t.co/sZJ04pgv3n']}"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adicionamos esses tweets a um DataFrame, para poder manipular os dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "#8\n",
    "dfTweets = pd.DataFrame.from_dict(tweets_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostramos os primeiros 5 dados do nosso DataFrame:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "#9\n",
    "dfTweets.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       created_at  \\\n",
       "0  Sun Aug 01 17:49:32 +0000 2021   \n",
       "\n",
       "                                           full_text  \n",
       "0  Sociedade\\nHá mais 28 mortes e 1.513 infecções...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 01 17:49:32 +0000 2021</td>\n",
       "      <td>Sociedade\\nHá mais 28 mortes e 1.513 infecções...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "E aqui, alteramos os nomes das colunas para português."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "#10\n",
    "dfTweets.rename(columns={\"full_text\": \"Texto\", \"created_at\": \"Data de criação\"})"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Data de criação  \\\n",
       "0  Sun Aug 01 17:49:32 +0000 2021   \n",
       "\n",
       "                                               Texto  \n",
       "0  Sociedade\\nHá mais 28 mortes e 1.513 infecções...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data de criação</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 01 17:49:32 +0000 2021</td>\n",
       "      <td>Sociedade\\nHá mais 28 mortes e 1.513 infecções...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por fim, adicionamos uma coluna chamada \"Sentimento\", aonde será colocada a anotação manual do sentimento de cada um desses tweets, e salvamos o DataFrame em um arquivo Excel, aonde é mais simples a manipulação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "#11\n",
    "dfTweets.insert(2, \"Sentimento1\", \" \")\n",
    "dfTweets.insert(3, \"Sentimento2\", \" \")\n",
    "dfTweets.insert(4, \"SentimentoFinal\", \" \")\n",
    "dfTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TweetsColetadosCovid.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos dividir e duplicar os datasets binários!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBinary = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflix.xlsx', index_col=0,  engine='openpyxl') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "newTweets = tweetsToBinary[tweetsToBinary['SentimentoFinal'] != 0]\n",
    "#newTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixBin.xlsx\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos balancear o dataset já existente entre neutros, positivos e negativos!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBalance = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTeste.xlsx', index_col=0,  engine='openpyxl')\n",
    "tweetsNeutral = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 0]\n",
    "tweetsPositive = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 1]\n",
    "tweetsNegative = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 2]\n",
    "\n",
    "print(len(tweetsNeutral))\n",
    "print(len(tweetsPositive))\n",
    "print(len(tweetsNegative))\n",
    "#df.index[[1,3]], inplace=True\n",
    "newTweetNeutral = tweetsNeutral.drop(tweetsNeutral.index[[range(0,41)]])\n",
    "newTweetPositive = tweetsPositive\n",
    "newTweetNegative = tweetsNegative.drop(tweetsNegative.index[[range(0,82)]])\n",
    "print(len(newTweetNeutral))\n",
    "print(len(newTweetPositive))\n",
    "print(len(newTweetNegative))\n",
    "\n",
    "newTweetList = pd.concat([newTweetNeutral, newTweetPositive, newTweetNegative])\n",
    "print(len(newTweetList))\n",
    "# shuffle the DataFrame rows\n",
    "df = newTweetList.sample(frac = 1)\n",
    "df\n",
    "#df.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBalenceada.xlsx\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n",
      "59\n",
      "141\n",
      "59\n",
      "59\n",
      "59\n",
      "177\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:4107: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos balancear o dataset binário!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBinaryBalance = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBalenceada.xlsx', index_col=0,  engine='openpyxl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "newTweets = tweetsToBinaryBalance[tweetsToBinaryBalance['SentimentoFinal'] != 0]\n",
    "#newTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceado.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, já deve ter sido realizada a anotação manual dos tweets!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tendo feita a anotação manual dos tweets, que no caso desse trabalho foi feito por 3 pessoas, adicionamos a tabela excel em uma variavel chamada tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "source": [
    "#12\n",
    "tweets= pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceado.xlsx', index_col=0,  engine='openpyxl') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vemos como ficou nossa tabela.\n",
    "Lembrando que tweets classificados como 0 são negativos, como 1 são positivos e como 2 são neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "source": [
    "#13\n",
    "tweets = tweets.reset_index()\n",
    "tweets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     index                                          full_text  Sentimento1  \\\n",
       "0      195  🤔 Não sabia desses dados? Curtiu a informação?...            2   \n",
       "1      294  Até agora temos no Brasil:\\n\\n-14237078 casos ...            2   \n",
       "2      211  COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO i...            2   \n",
       "3      140  Comando Conjunto Leste (C Cj L), em parceria c...            1   \n",
       "4      194  A seção voltada aos povos indígenas do guia Im...            2   \n",
       "..     ...                                                ...          ...   \n",
       "113    206  SAIU! JAILBREAK CHECKRA1N PARA IOS 14.4.2 | FA...            2   \n",
       "114    151  💉Vacinação em Macaé &lt;&lt;\\n\\nFique ligado n...            1   \n",
       "115    200  INSTALOU O iOS 14? SAIBA COMO VOLTAR PARA O iO...            2   \n",
       "116     69  Em Cuba, a vacina é SOBERANA. Até o nome é lin...            1   \n",
       "117     87  Zero Mortes de Covid foi alcançada em Israel ,...            1   \n",
       "\n",
       "     Sentimento2  SentimentoFinal  \n",
       "0              2                2  \n",
       "1              2                2  \n",
       "2              2                2  \n",
       "3              1                1  \n",
       "4              2                2  \n",
       "..           ...              ...  \n",
       "113            2                2  \n",
       "114            2                1  \n",
       "115            2                2  \n",
       "116            1                1  \n",
       "117            1                1  \n",
       "\n",
       "[118 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>🤔 Não sabia desses dados? Curtiu a informação?...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294</td>\n",
       "      <td>Até agora temos no Brasil:\\n\\n-14237078 casos ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO i...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>Comando Conjunto Leste (C Cj L), em parceria c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>A seção voltada aos povos indígenas do guia Im...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>206</td>\n",
       "      <td>SAIU! JAILBREAK CHECKRA1N PARA IOS 14.4.2 | FA...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>151</td>\n",
       "      <td>💉Vacinação em Macaé &amp;lt;&amp;lt;\\n\\nFique ligado n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>200</td>\n",
       "      <td>INSTALOU O iOS 14? SAIBA COMO VOLTAR PARA O iO...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>69</td>\n",
       "      <td>Em Cuba, a vacina é SOBERANA. Até o nome é lin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>87</td>\n",
       "      <td>Zero Mortes de Covid foi alcançada em Israel ,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 510
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A seguir, iniciaremos o trabalho de pré-processamento dos tweets dos nossos datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### O pré-processamento tem como objetivo deixar o texto presente nos tweets mais \"limpo\". Está sendo feito com apenas 1 dataset, apenas como exemplo, mas a técnica foi aplicada nos 3 datasets. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos utilizar um tweet como exemplo para que possa ser verificada o resultado de cada uma das tarefas de pré-processamento."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "source": [
    "#14\n",
    "exemploPreProcess = (tweets.at[2,'full_text'])\n",
    "print (exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO iPhone em 2021 | INFALÍVEL\n",
      "https://t.co/0c4D9ZKajo\n",
      "\n",
      " #google #CoronaVac #coronavirus #apple #ios #iphone #AppleRetweetBot #vemvacina #bbb21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para a tokenização dos tweets (separar a frase em pequenos termos que façam sentido), utilizamos uma biblioteca específica para tweets. Ela auxilia na separação de emojis, hashtags, menções e outras questões próprias do Twitter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "source": [
    "#15\n",
    "tweet_tokenize = TweetTokenizer()\n",
    "tweet_tokenize.tokenize(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['COMO',\n",
       " '#SINCRONIZAR',\n",
       " 'OS',\n",
       " '#CONTATOS',\n",
       " 'DO',\n",
       " '#GOOGLE',\n",
       " 'NO',\n",
       " 'iPhone',\n",
       " 'em',\n",
       " '2021',\n",
       " '|',\n",
       " 'INFALÍVEL',\n",
       " 'https://t.co/0c4D9ZKajo',\n",
       " '#google',\n",
       " '#CoronaVac',\n",
       " '#coronavirus',\n",
       " '#apple',\n",
       " '#ios',\n",
       " '#iphone',\n",
       " '#AppleRetweetBot',\n",
       " '#vemvacina',\n",
       " '#bbb21']"
      ]
     },
     "metadata": {},
     "execution_count": 512
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A seguir, baixamos uma base de \"stopwords\" em português. Stopwords são palavras que não agregam sentido ao texto. Artigos e preposições são exemplos de stopwords."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "source": [
    "#16\n",
    "try:\n",
    "     _create_unverified_https_context =     ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "     pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download('stopwords')\n",
    "def RemoveStopWords(tweet):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    textInWords = []\n",
    "    for word in tweet.lower().split():\n",
    "        if (word not in stopwords) and (word.isdigit() == False): \n",
    "            textInWords.append(word)\n",
    "\n",
    "    res = ' '.join(map(str, textInWords))\n",
    "    return res"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver abaixo como fica o tweet após a remoção de suas stopwords."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "source": [
    "#17\n",
    "RemoveStopWords(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'#sincronizar #contatos #google iphone | infalível https://t.co/0c4d9zkajo #google #coronavac #coronavirus #apple #ios #iphone #appleretweetbot #vemvacina #bbb21'"
      ]
     },
     "metadata": {},
     "execution_count": 514
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para fazer a stemização de cada tweet (deixar apenas a raiz(radical) de cada termo), utilizamos uma biblioteca própria que nos ajuda a fazer isso. Essa bibloteca é específica para português. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "source": [
    "#18\n",
    "nltk.download('rslp')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 515
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "source": [
    "#19\n",
    "#stemmer = nltk.stem.porter.PorterStemmer()\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tweet):\n",
    "    textInWords = []\n",
    "    for word in tweet.lower().split():\n",
    "        textInWords.append(stemmer.stem(word))\n",
    "    res = ' '.join(map(str, textInWords))\n",
    "    return res\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver abaixo como fica o tweet após a sua stemização."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "source": [
    "#20\n",
    "stem_tokens(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'com #sincron os #contat do #googl no iphon em 2021 | infal https://t.co/0c4d9zkaj #googl #coronavac #coronaviru #appl #io #iphon #appleretweetbot #vemvacin #bbb21'"
      ]
     },
     "metadata": {},
     "execution_count": 517
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, temos uma função de \"limpeza\". Nela, são excluídas quaisquer caracteres que não são letras. Também são excluídos links, hashtags e emojis. Todas as letras são passadas para minúsculo. Além disso, são excluídos dígitos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "source": [
    "#21\n",
    "def Limpa_dados(tweet): ##M MUDAR NOME DESSA FUNCAO\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets E ACENTOS\n",
    "    tweet = unidecode(re.sub(r\"http\\S+\", \"\", tweet).lower().replace('.','')\n",
    "                      .replace(';','').replace('+','').replace(']','').replace('[','').replace('\\'','').replace(';','').replace('%','').replace('-',' ').replace(',',' ')\n",
    "                      .replace('\\n','').replace('\\\"','').replace(')','').replace('(','').replace('$','').replace('?','')\n",
    "                      .replace('_','').replace(':','').replace('!','').replace('|','').replace('/','').replace(')',''))\n",
    "    tweet = unidecode(re.sub(r\"@[A-Za-z0-9]+\", \"\", tweet))\n",
    "    tweet = unidecode(re.sub(r\"\\#[A-Za-z0-9]+\", \"\", tweet))\n",
    "    \n",
    "    tweet = unidecode(re.sub(r\"[0-9]+[A-Za-z0-9]+\", \"\", tweet)) #Remove digitos\n",
    "    tweet = tweet.replace('  ', ' ') #Corrige espaços feitos a mais.\n",
    "    tweet = tweet.replace('[?]', ' ') #Corrige outros errinhos.\n",
    "    return (tweet)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vemos o tweets após a sua \"limpeza\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "source": [
    "#22\n",
    "Limpa_dados(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'como os do no iphone em  infalivel     '"
      ]
     },
     "metadata": {},
     "execution_count": 519
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por fim, executamos as 3 funções de pré-processamento e adicionamos a uma nova tabela Excel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "source": [
    "#23\n",
    "#PreProcessa todos os tweets:\n",
    "\n",
    "qtdTweets = len(tweets)\n",
    "for tweet in range (qtdTweets):\n",
    "    tweets.at[tweet, 'full_text'] =  Limpa_dados(str(tweets.at[tweet, 'full_text']))\n",
    "    tweets.at[tweet, 'full_text'] =  RemoveStopWords(str(tweets.at[tweet, 'full_text']))\n",
    "    tweets.at[tweet, 'full_text'] =  stem_tokens(str(tweets.at[tweet, 'full_text']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "source": [
    "#24\n",
    "#tweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceadoPreProcessados.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Começaremos então o processo de treinamento por parte dos algoritmos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primeiramente, pegamos os dados de treinamento e teste. Aqui estaremos treinando o algoritmo com os dados de covid (700 tweets) e testando com os dados de covid (300 tweets). Os dados vem de tabelas diferentes e são diferentes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "source": [
    "dadosTreino = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTreinoPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "dadosTeste = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTestePreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "source": [
    "dadosTreino.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  notic hor vai vacin nest feri enta fiqu atent ...            2   \n",
       "1           1  import pal expliqu importanc med prevenca cont...            2   \n",
       "2           2  veicul cont sistem mens som informaco utel pop...            2   \n",
       "3           3  beij temp cris sar arapiun edn arapiun devid v...            2   \n",
       "4           4  despach intim presid jair bolsonar ministr sau...            2   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            2                2  \n",
       "1            2                2  \n",
       "2            2                2  \n",
       "3            2                2  \n",
       "4            2                2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>notic hor vai vacin nest feri enta fiqu atent ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>import pal expliqu importanc med prevenca cont...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>veicul cont sistem mens som informaco utel pop...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>beij temp cris sar arapiun edn arapiun devid v...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>despach intim presid jair bolsonar ministr sau...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 523
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "source": [
    "dadosTeste.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  assum risc tom morr pesquis demonstr cloroquin...            0   \n",
       "1           1  ind imag hospit gtb nov delh vari paci esta es...            0   \n",
       "2           2  brasil numer suspeit cas confirm numer mort re...            2   \n",
       "3           3  boletim check up saudeol vej aco melhor saud d...            2   \n",
       "4           4    catorz est distrit feder mant ocupaca util acim            0   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            0                0  \n",
       "1            2                0  \n",
       "2            2                2  \n",
       "3            2                2  \n",
       "4            0                0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>assum risc tom morr pesquis demonstr cloroquin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ind imag hospit gtb nov delh vari paci esta es...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brasil numer suspeit cas confirm numer mort re...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>boletim check up saudeol vej aco melhor saud d...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>catorz est distrit feder mant ocupaca util acim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 524
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos pegar os textos dos tweets de treinamento e teste e seus respectivos sentimentos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "source": [
    "tweetsParaTreino = dadosTreino['full_text'].values\n",
    "classesParaTreino = dadosTreino['SentimentoFinal'].values\n",
    "tweetsParaTeste = dadosTeste['full_text'].values\n",
    "classesParaTeste = dadosTeste['SentimentoFinal'].values\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos a técnica Holdout, separando os dados em 70% para treinamento e 30% para teste."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "source": [
    "qtdTweetsTreino = len(dadosTreino)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 526
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "source": [
    "qtdTweetsTeste = len(dadosTeste)\n",
    "qtdTweetsTeste"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 527
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqui, instanciamos o vetorizador dos tweets. Ele é responsável pela transformação dos dados textuais em um formato que o algoritmo entenda. É utilizada a técnica Bag Of Words, aonde as palavras viram colunas em uma tabela e cada tweet terá uma representação de 0's e 1's. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vetorizamos os dados de treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "source": [
    "vect_tweetsTreino = vectorizer.fit_transform(tweetsParaTreino) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, faremos o treinamento do algoritmo. Utilizamos o algoritmo Multinomial Naive Bayes, o SVM."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "source": [
    "classificador = MultinomialNB()\n",
    "classificadorBerno = BernoulliNB()\n",
    "classificadorComplement = ComplementNB()\n",
    "classificador.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "classificadorBerno.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "classificadorComplement.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "\n",
    "classificadorSVM = svm.SVC(kernel='linear')\n",
    "classificadorSVM.fit(vect_tweetsTreino, classesParaTreino)\n",
    "\n",
    "classificadorLR = LogisticRegression(random_state=0).fit(vect_tweetsTreino, classesParaTreino)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Já tendo o algoritmo sido treinado, faremos a vetorização dos dados de teste."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "source": [
    "vect_tweetsTeste = vectorizer.transform(tweetsParaTeste) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, fazemos a predição dos dados de teste por parte do algoritmo já treinado."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "source": [
    "result = classificador.predict(vect_tweetsTeste)\n",
    "resultBerno = classificadorBerno.predict(vect_tweetsTeste)\n",
    "resultComplement = classificadorComplement.predict(vect_tweetsTeste)\n",
    "resultSVM = classificadorSVM.predict(vect_tweetsTeste)\n",
    "resultLR = classificadorLR.predict(vect_tweetsTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agora já possuímos o algoritmo treinado e os dados para verificar o resultado nos testes. Vamos prosseguir vendo o resultado das métricas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos ver a acurácia primeiramente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "source": [
    "acc = accuracy_score(classesParaTeste, result) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTeste, resultSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTeste, resultLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTeste, resultBerno) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTeste, resultComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63.0% \n",
      "60.33% \n",
      "63.67% \n",
      "63.67% \n",
      "63.67% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos verificar a matriz de confusão agora. Ela tem o objetivo de ver em que classes o algoritmo conseguiu classificar melhor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "source": [
    "print (pd.crosstab(classesParaTeste, result, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito    0   1    2  All\n",
      "Real                      \n",
      "0         83   6   11  100\n",
      "1         20  22   17   59\n",
      "2         41  16   84  141\n",
      "All      144  44  112  300\n",
      "Predito   0  1    2  All\n",
      "Real                    \n",
      "0        42  2   56  100\n",
      "1        13  2   44   59\n",
      "2        10  1  130  141\n",
      "All      65  5  230  300\n",
      "Predito    0   1    2  All\n",
      "Real                      \n",
      "0         76   8   16  100\n",
      "1         16  31   12   59\n",
      "2         42  19   80  141\n",
      "All      134  58  108  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos verificar, por fim, as outras métricas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "source": [
    "print(classification_report(classesParaTeste, result, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultLR, labels = [0,1,2]))\n",
    "\n",
    "print(classification_report(classesParaTeste, resultBerno, labels = [0,1,2]))\n",
    "\n",
    "print(classification_report(classesParaTeste, resultComplement, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68       100\n",
      "           1       0.50      0.37      0.43        59\n",
      "           2       0.75      0.60      0.66       141\n",
      "\n",
      "    accuracy                           0.63       300\n",
      "   macro avg       0.61      0.60      0.59       300\n",
      "weighted avg       0.64      0.63      0.62       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.42      0.51       100\n",
      "           1       0.40      0.03      0.06        59\n",
      "           2       0.57      0.92      0.70       141\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.54      0.46      0.42       300\n",
      "weighted avg       0.56      0.58      0.51       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.76      0.65       100\n",
      "           1       0.53      0.53      0.53        59\n",
      "           2       0.74      0.57      0.64       141\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.61      0.62      0.61       300\n",
      "weighted avg       0.64      0.62      0.62       300\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agora, faremos o treinamento com os dados da tabela de assuntos diversos (700 tweets). A tabela de teste segue sendo a mesma."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esse processo é semelhante ao feito anteriormente, então não há necessidade de explicar cada etapa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "source": [
    "dadosTreinoDiversos = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosPreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "source": [
    "dadosTreinoDiversos.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  ant malest coa falt dialog med xunt propux abr...            0   \n",
       "1           1                       pra gast pod gast pouc acess            2   \n",
       "2           2              oposica reform tribut desconhec lobby            0   \n",
       "3           3                  importanc poupanc composica setor            1   \n",
       "4           4                                  \"pib governo\" err            0   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            0                0  \n",
       "1            2                2  \n",
       "2            2                2  \n",
       "3            1                1  \n",
       "4            2                0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ant malest coa falt dialog med xunt propux abr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pra gast pod gast pouc acess</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>oposica reform tribut desconhec lobby</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>importanc poupanc composica setor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"pib governo\" err</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 537
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "source": [
    "tweetsParaTreinoDiversos = dadosTreinoDiversos['full_text'].values\n",
    "classesParaTreinoDiversos = dadosTreinoDiversos['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "source": [
    "qtdTweetsTreino = len(dadosTreinoDiversos)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 539
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "source": [
    "vect_tweetsTreinoDiversos = vectorizer.fit_transform(tweetsParaTreinoDiversos)  #treina com diversos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "source": [
    "classificadorDiversos = MultinomialNB()\n",
    "classificadorDiversos.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorDiversosBerno = BernoulliNB()\n",
    "classificadorDiversosBerno.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorDiversosComplement = ComplementNB()\n",
    "classificadorDiversosComplement.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorSVMDiv = svm.SVC(kernel='linear')\n",
    "classificadorSVMDiv.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos)\n",
    "\n",
    "classificadorLRDiv = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "source": [
    "vect_tweetsTeste = vectorizer.transform(tweetsParaTeste) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "source": [
    "resultDiversos = classificadorDiversos.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosBerno = classificadorDiversosBerno.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosComplement = classificadorDiversosComplement.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosSVM = classificadorSVMDiv.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosLR = classificadorLRDiv.predict(vect_tweetsTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "source": [
    "acc = accuracy_score(classesParaTeste, resultDiversos) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTeste, resultDiversosSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTeste, resultDiversosLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTeste, resultDiversosBerno) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTeste, resultDiversosComplement) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "55.0% \n",
      "61.67% \n",
      "58.0% \n",
      "55.0% \n",
      "55.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "source": [
    "print (pd.crosstab(classesParaTeste, resultDiversos, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultDiversosSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultDiversosLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultDiversosBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultDiversosComplement, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        40  17   43  100\n",
      "1         5  32   22   59\n",
      "2        19  29   93  141\n",
      "All      64  78  158  300\n",
      "Predito  0   1    2  All\n",
      "Real                    \n",
      "0        5   3   92  100\n",
      "1        0   6   53   59\n",
      "2        0   3  138  141\n",
      "All      5  12  283  300\n",
      "Predito   0    1    2  All\n",
      "Real                      \n",
      "0        52   25   23  100\n",
      "1         6   39   14   59\n",
      "2        31   40   70  141\n",
      "All      89  104  107  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "source": [
    "print(classification_report(classesParaTeste, resultDiversos, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTeste, resultDiversosBerno, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTeste, resultDiversosComplement, labels = [0,1,2]))\n",
    "\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultDiversosSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultDiversosLR, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.49       100\n",
      "           1       0.41      0.54      0.47        59\n",
      "           2       0.59      0.66      0.62       141\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.54      0.53      0.53       300\n",
      "weighted avg       0.57      0.55      0.55       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10       100\n",
      "           1       0.50      0.10      0.17        59\n",
      "           2       0.49      0.98      0.65       141\n",
      "\n",
      "    accuracy                           0.50       300\n",
      "   macro avg       0.66      0.38      0.31       300\n",
      "weighted avg       0.66      0.50      0.37       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       100\n",
      "           1       0.38      0.66      0.48        59\n",
      "           2       0.65      0.50      0.56       141\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.54      0.56      0.53       300\n",
      "weighted avg       0.58      0.54      0.54       300\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agora faremos a classificação em tabelas binárias, aonde há apenas as classes positiva e negativa (1 e 0)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para tal, foram feitas cópias dos 3 datasets e excluídos os tweets neutros nessas cópias. Assim, faremos o treinamento e teste novamente nestes datasets.\n",
    "Este processo já foi explicado anteriormente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "source": [
    "dadosTreinoBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTreinoBinPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "dadosTesteBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinPreProcessados.xlsx',engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "source": [
    "len(dadosTreinoBin)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "metadata": {},
     "execution_count": 564
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "source": [
    "len(dadosTesteBin)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 565
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "source": [
    "tweetsParaTreinoBin = dadosTreinoBin['full_text'].values\n",
    "classesParaTreinoBin = dadosTreinoBin['SentimentoFinal'].values\n",
    "tweetsParaTesteBin = dadosTesteBin['full_text'].values\n",
    "classesParaTesteBin = dadosTesteBin['SentimentoFinal'].values\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "source": [
    "vect_tweetsTreinoBin = vectorizer.fit_transform(tweetsParaTreinoBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "source": [
    "classificadorBin = MultinomialNB()\n",
    "classificadorBin.fit(vect_tweetsTreinoBin, classesParaTreinoBin)\n",
    "\n",
    "classificadorBinBerno = BernoulliNB()\n",
    "classificadorBinBerno.fit(vect_tweetsTreinoBin, classesParaTreinoBin) \n",
    "\n",
    "classificadorBinComplement = ComplementNB()\n",
    "classificadorBinComplement.fit(vect_tweetsTreinoBin, classesParaTreinoBin) \n",
    "\n",
    "classificadorSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorSVMBin.fit(vect_tweetsTreinoBin, classesParaTreinoBin)\n",
    "\n",
    "classificadorLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoBin, classesParaTreinoBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "source": [
    "vect_tweetsTesteBin = vectorizer.transform(tweetsParaTesteBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "source": [
    "resultBin = classificadorBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinBerno = classificadorBinBerno.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinComplement = classificadorBinComplement.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinSVM = classificadorSVMBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinLR = classificadorLRBin.predict(vect_tweetsTesteBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "source": [
    "acc = accuracy_score(classesParaTesteBin, resultBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteBin, resultBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteBin, resultBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteBin, resultBinBerno) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteBin, resultBinComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74.5% \n",
      "78.0% \n",
      "80.0% \n",
      "78.0% \n",
      "80.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "source": [
    "print (pd.crosstab(classesParaTesteBin, resultBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultBinLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultBinBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultBinComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        38   21   59\n",
      "2        30  111  141\n",
      "All      68  132  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        10   49   59\n",
      "2         5  136  141\n",
      "All      15  185  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        42   17   59\n",
      "2        43   98  141\n",
      "All      85  115  200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "source": [
    "print(classification_report(classesParaTesteBin, resultBin, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultBinSVM, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultBinLR, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultBinBerno, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultBinComplement, labels = [0,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.56      0.64      0.60        59\n",
      "\n",
      "   micro avg       0.56      0.64      0.60        59\n",
      "   macro avg       0.28      0.32      0.30        59\n",
      "weighted avg       0.56      0.64      0.60        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.67      0.17      0.27        59\n",
      "\n",
      "   micro avg       0.67      0.17      0.27        59\n",
      "   macro avg       0.33      0.08      0.14        59\n",
      "weighted avg       0.67      0.17      0.27        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.49      0.71      0.58        59\n",
      "\n",
      "   micro avg       0.49      0.71      0.58        59\n",
      "   macro avg       0.25      0.36      0.29        59\n",
      "weighted avg       0.49      0.71      0.58        59\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Agora faremos o treinamento com o dataset de assuntos diversos sem os tweets neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('TabelaDiversosBinPreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "source": [
    "tweetsParaTreinoDiversosBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDiversosBin = dadosTreinoDiversosBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "source": [
    "qtdTweetsTreinoBin = len(dadosTreinoDiversosBin)\n",
    "qtdTweetsTreinoBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "metadata": {},
     "execution_count": 584
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "source": [
    "vect_tweetsTreinoDiversosBin = vectorizer.fit_transform(tweetsParaTreinoDiversosBin)  #treina com diversos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "source": [
    "classificadorDiversosBin = MultinomialNB()\n",
    "classificadorDiversosBin.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorDiversosBinBerno = BernoulliNB()\n",
    "classificadorDiversosBinBerno.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin) \n",
    "\n",
    "classificadorDiversosBinComplement = ComplementNB()\n",
    "classificadorDiversosBinComplement.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin) \n",
    "\n",
    "classificadorDiversosSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorDiversosSVMBin.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorDiversosLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "source": [
    "vect_tweetsTesteBin = vectorizer.transform(tweetsParaTesteBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "source": [
    "resultDiversosBin = classificadorDiversosBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinBerno = classificadorDiversosBinBerno.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinComplement = classificadorDiversosBinComplement.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinSVM = classificadorDiversosSVMBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinLR = classificadorDiversosLRBin.predict(vect_tweetsTesteBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "source": [
    "acc = accuracy_score(classesParaTesteBin, resultDiversosBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteBin, resultDiversosBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteBin, resultDiversosBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteBin, resultDiversosBinBerno) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteBin, resultDiversosBinComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69.0% \n",
      "80.0% \n",
      "78.5% \n",
      "80.0% \n",
      "78.5% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "source": [
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultDiversosBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultDiversosBinLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBinBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBinComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        36   23   59\n",
      "2        39  102  141\n",
      "All      75  125  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1         7   52   59\n",
      "2         5  136  141\n",
      "All      12  188  200\n",
      "Predito    1   2  All\n",
      "Real                 \n",
      "1         45  14   59\n",
      "2         62  79  141\n",
      "All      107  93  200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "source": [
    "print(classification_report(classesParaTesteBin, resultDiversosBin, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultDiversosBinSVM, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultDiversosBinLR, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultDiversosBinBerno, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultDiversosBinComplement, labels = [0,1]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.48      0.61      0.54        59\n",
      "\n",
      "   micro avg       0.48      0.61      0.54        59\n",
      "   macro avg       0.24      0.31      0.27        59\n",
      "weighted avg       0.48      0.61      0.54        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.58      0.12      0.20        59\n",
      "\n",
      "   micro avg       0.58      0.12      0.20        59\n",
      "   macro avg       0.29      0.06      0.10        59\n",
      "weighted avg       0.58      0.12      0.20        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.42      0.76      0.54        59\n",
      "\n",
      "   micro avg       0.42      0.76      0.54        59\n",
      "   macro avg       0.21      0.38      0.27        59\n",
      "weighted avg       0.42      0.76      0.54        59\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teste cruzado com  #netflix binário"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosBinPreProcessados.xlsx',  engine='openpyxl').fillna(' ')\n",
    "dadosTesteNetflixBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixBinPreProcessados.xlsx',  engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "source": [
    "tweetsParaTreinoDivBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDivBin = dadosTreinoDiversosBin['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflixBin = dadosTesteNetflixBin['full_text'].values\n",
    "classesParaTesteNetflixBin = dadosTesteNetflixBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "source": [
    "qtdTweetsTreinoBin = len(dadosTreinoDiversosBin)\n",
    "qtdTweetsTreinoBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "metadata": {},
     "execution_count": 680
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "source": [
    "qtdTweetsTesteBin = len(dadosTesteNetflixBin)\n",
    "qtdTweetsTesteBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "metadata": {},
     "execution_count": 681
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer_bin = TweetTokenizer() \n",
    "vectorizerBin = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer_bin.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "source": [
    "vect_tweetsTreinoDivBin = vectorizerBin.fit_transform(tweetsParaTreinoDivBin)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "source": [
    "classificadorValidBin = MultinomialNB()\n",
    "classificadorValidBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)\n",
    "\n",
    "classificadorValidBernoBin = BernoulliNB()\n",
    "classificadorValidBernoBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin) \n",
    "\n",
    "classificadorValidComplementBin = ComplementNB()\n",
    "classificadorValidComplementBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin) \n",
    "\n",
    "classificadorValidSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorValidSVMBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)\n",
    "\n",
    "classificadorValidLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "source": [
    "vect_tweetsTesteNetflixBin = vectorizerBin.transform(tweetsParaTesteNetflixBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "source": [
    "resultValidBin = classificadorValidBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBernoBin = classificadorValidBernoBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidComplementBin = classificadorValidComplementBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidSVMBin = classificadorValidSVMBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidLRBin = classificadorValidLRBin.predict(vect_tweetsTesteNetflixBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflixBin, resultValidBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflixBin, resultValidSVMBin) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflixBin, resultValidLRBin) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteNetflixBin, resultValidBernoBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteNetflixBin, resultValidComplementBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "66.95% \n",
      "67.36% \n",
      "70.71% \n",
      "66.95% \n",
      "66.95% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBernoBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidComplementBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflixBin, resultValidSVMBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflixBin, resultValidLRBin, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        13   53   66\n",
      "2        26  147  173\n",
      "All      39  200  239\n",
      "Predito  1    2  All\n",
      "Real                \n",
      "1        2   64   66\n",
      "2        1  172  173\n",
      "All      3  236  239\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        23   43   66\n",
      "2        50  123  173\n",
      "All      73  166  239\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Por fim, vamos validar os resultados realizando o treinamento com os tweets de assuntos diversos e o teste com os tweets #netflix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esta etapa de treinamento/teste é como as anteriores, logo, não há necessidade de explicar cada passo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "source": [
    "dadosTreinoDiversos = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosPreProcessados.xlsx',  engine='openpyxl').fillna(' ')\n",
    "dadosTesteNetflix = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixPreProcessados.xlsx',  engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "source": [
    "tweetsParaTreinoDiv = dadosTreinoDiversos['full_text'].values\n",
    "classesParaTreinoDiv = dadosTreinoDiversos['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflix = dadosTesteNetflix['full_text'].values\n",
    "classesParaTesteNetflix = dadosTesteNetflix['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "source": [
    "qtdTweetsTreino = len(dadosTreinoDiversos)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 616
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "source": [
    "qtdTweetsTeste = len(dadosTesteNetflix)\n",
    "qtdTweetsTeste"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 617
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "source": [
    "vect_tweetsTreinoDiv = vectorizer.fit_transform(tweetsParaTreinoDiv)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "source": [
    "classificadorValid = MultinomialNB()\n",
    "classificadorValid.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)\n",
    "\n",
    "classificadorValidBerno = BernoulliNB()\n",
    "classificadorValidBerno.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv) \n",
    "\n",
    "classificadorValidComplement = ComplementNB()\n",
    "classificadorValidComplement.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv) \n",
    "\n",
    "classificadorValidSVM = svm.SVC(kernel='linear')\n",
    "classificadorValidSVM.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)\n",
    "\n",
    "classificadorValidLR = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "source": [
    "vect_tweetsTesteNetflix = vectorizer.transform(tweetsParaTesteNetflix) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "source": [
    "resultValid = classificadorValid.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidBerno = classificadorValidBerno.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidComplement = classificadorValidComplement.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidSVM = classificadorValidSVM.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidLR = classificadorValidLR.predict(vect_tweetsTesteNetflix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflix, resultValid) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflix, resultValidSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflix, resultValidLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteNetflix, resultValidBerno) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteNetflix, resultValidComplement) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "54.0% \n",
      "56.33% \n",
      "57.33% \n",
      "54.0% \n",
      "54.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflix, resultValid, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflix, resultValidBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflix, resultValidComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflix, resultValidSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflix, resultValidLR, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        15   5   41   61\n",
      "1         6   9   51   66\n",
      "2        10  25  138  173\n",
      "All      31  39  230  300\n",
      "Predito  1    2  All\n",
      "Real                \n",
      "0        0   61   61\n",
      "1        2   64   66\n",
      "2        0  173  173\n",
      "All      2  298  300\n",
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        25   8   28   61\n",
      "1        20  17   29   66\n",
      "2        32  37  104  173\n",
      "All      77  62  161  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "source": [
    "print(classification_report(classesParaTesteNetflix, resultValid, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteNetflix, resultValidBerno, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteNetflix, resultValidComplement, labels = [0,1,2]))\n",
    "\n",
    "\n",
    "#print(classification_report(classesParaTesteNetflix, resultValidSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTesteNetflix, resultValidLR, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.25      0.33        61\n",
      "           1       0.23      0.14      0.17        66\n",
      "           2       0.60      0.80      0.68       173\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.44      0.39      0.39       300\n",
      "weighted avg       0.50      0.54      0.50       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        61\n",
      "           1       1.00      0.03      0.06        66\n",
      "           2       0.58      1.00      0.73       173\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.53      0.34      0.26       300\n",
      "weighted avg       0.55      0.58      0.44       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.41      0.36        61\n",
      "           1       0.27      0.26      0.27        66\n",
      "           2       0.65      0.60      0.62       173\n",
      "\n",
      "    accuracy                           0.49       300\n",
      "   macro avg       0.41      0.42      0.42       300\n",
      "weighted avg       0.50      0.49      0.49       300\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, o treinamento/teste aonde sem tweets neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('TabelaDiversosPreProcessadosBin.xlsx').fillna(' ')\n",
    "dadosTesteNetflixBin = pd.read_excel('TabelaNetflixPreProcessadosBin.xlsx').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "tweetsParaTreinoDiversosBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDiversosBin = dadosTreinoDiversosBin['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflixBin = dadosTesteNetflixBin['full_text'].values\n",
    "classesParaTesteNetflixBin = dadosTesteNetflixBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "vect_tweetsTreinoBin = vectorizer.fit_transform(tweetsParaTreinoDiversosBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "classificadorBinValid = MultinomialNB()\n",
    "classificadorBinValid.fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorBinValidSVM = svm.SVC(kernel='linear')\n",
    "classificadorBinValidSVM.fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorBinValidLR = LogisticRegression(random_state=0).fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "vect_tweetsTesteNetflixBin = vectorizer.transform(tweetsParaTesteNetflixBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "resultValidBin = classificadorBinValid.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBinSVM = classificadorBinValidSVM.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBinLR = classificadorBinValidLR.predict(vect_tweetsTesteNetflixBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflixBin, resultValidBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflixBin, resultValidBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflixBin, resultValidBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68.5% \n",
      "65.35% \n",
      "66.14% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBinLR, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1  All\n",
      "Real                \n",
      "0        44  18   62\n",
      "1        22  43   65\n",
      "All      66  61  127\n",
      "Predito   0   1  All\n",
      "Real                \n",
      "0        35  27   62\n",
      "1        17  48   65\n",
      "All      52  75  127\n",
      "Predito   0   1  All\n",
      "Real                \n",
      "0        33  29   62\n",
      "1        14  51   65\n",
      "All      47  80  127\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "print(classification_report(classesParaTesteNetflixBin, resultValidBin, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteNetflixBin, resultValidBinSVM, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteNetflixBin, resultValidBinLR, labels = [0,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69        62\n",
      "          1       0.70      0.66      0.68        65\n",
      "\n",
      "avg / total       0.69      0.69      0.68       127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.56      0.61        62\n",
      "          1       0.64      0.74      0.69        65\n",
      "\n",
      "avg / total       0.66      0.65      0.65       127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.53      0.61        62\n",
      "          1       0.64      0.78      0.70        65\n",
      "\n",
      "avg / total       0.67      0.66      0.66       127\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "###### Obrigado por olhar o meu notebook! Fique livre para copiá-lo, altera-lo e utiliza-lo em seus estudos/projetos "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}