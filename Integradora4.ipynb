{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook da Integradora 4\n",
    "## Aluno: Thiago Medina\n",
    "## Orientadora: Isabel H. Manssour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, os imports necess√°rio para a realiza√ß√£o de todo o notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "#1\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install unidecode\n",
    "!{sys.executable} -m pip install tweepy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install ssl\n",
    "\n",
    "import ssl\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: regex in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: click in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: unidecode in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tweepy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: xlrd in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ssl\n",
      "  Using cached ssl-1.16.tar.gz (33 kB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[31m    ERROR: Command errored out with exit status 1:\r\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-pip-egg-info-csvejgj8\r\n",
      "         cwd: /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/\r\n",
      "    Complete output (6 lines):\r\n",
      "    Traceback (most recent call last):\r\n",
      "      File \"<string>\", line 1, in <module>\r\n",
      "      File \"/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-bdug9sug/ssl/setup.py\", line 33\r\n",
      "        print 'looking for', f\r\n",
      "              ^\r\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('looking for', f)?\r\n",
      "    ----------------------------------------\u001b[0m\r\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## O trabalho todo est√° separado em 3 partes:\n",
    "### 1- Coleta dos tweets\n",
    "### 2- Pr√©-processamento dos tweets.\n",
    "### 3- Treinamento e teste por parte do algoritmo\n",
    "\n",
    "Iniciamos com a coleta dos tweets:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Necess√°rio possuir suas chaves pr√≥prias para a coleta de tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "#2\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "#3\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "public_tweets = api.home_timeline()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query para a coleta de tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Altere a query de pesquisa (pode-se utilizar operadores l√≥gicos). Altere tamb√©m a quantidade de tweets que deseja coletar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "#4\n",
    "#query = '(#masterchef)  OR(#MasterChefBR) OR (#masterchefbrasil)  -filter:retweets'\n",
    "#query = '(#bbb21) -filter:retweets'\n",
    "query = '(#covid19) OR (#covid) OR (#coronavirus) -filter:retweets'\n",
    "#query = '(#educacao AND (-@mpsnet AND -@mpsnet2)) -filter:retweets'\n",
    "\n",
    "cursor_tweets = tw.Cursor(api.search,\n",
    "            q=query,lang = 'pt',tweet_mode='extended').items(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos apenas a coluna com o texto dos tweets e a data de cria√ß√£o dos mesmos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "#5\n",
    "tweets_dict = {}\n",
    "tweets_dict = tweets_dict.fromkeys(['created_at', 'full_text'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "#6\n",
    "for tweet in cursor_tweets:\n",
    "    for key in tweets_dict.keys():\n",
    "        try:\n",
    "            twvalue = tweet._json[key]\n",
    "            tweets_dict[key].append(twvalue)\n",
    "        except KeyError:\n",
    "            twvalue = \"\"\n",
    "            if(tweets_dict[key] is None):\n",
    "                tweets_dict[key] = [twvalue]\n",
    "            else:\n",
    "                tweets_dict[key].append(twvalue)\n",
    "        except:\n",
    "            tweets_dict[key] = [twvalue]\n",
    "        #print(\"tweets_dict[key]: {} - tweet[key]: {}\".format(tweets_dict[key],  twvalue))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, listamos os tweets coletados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "#7\n",
    "tweets_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'created_at': ['Sun Aug 01 17:49:32 +0000 2021'],\n",
       " 'full_text': ['Sociedade\\nH√° mais 28 mortes e 1.513 infec√ß√µes por Coronav√≠rus no pa√≠s\\n#covid19 #mocambique \\nhttps://t.co/sZJ04pgv3n']}"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adicionamos esses tweets a um DataFrame, para poder manipular os dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "#8\n",
    "dfTweets = pd.DataFrame.from_dict(tweets_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostramos os primeiros 5 dados do nosso DataFrame:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "#9\n",
    "dfTweets.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       created_at  \\\n",
       "0  Sun Aug 01 17:49:32 +0000 2021   \n",
       "\n",
       "                                           full_text  \n",
       "0  Sociedade\\nH√° mais 28 mortes e 1.513 infec√ß√µes...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 01 17:49:32 +0000 2021</td>\n",
       "      <td>Sociedade\\nH√° mais 28 mortes e 1.513 infec√ß√µes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "E aqui, alteramos os nomes das colunas para portugu√™s."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "#10\n",
    "dfTweets.rename(columns={\"full_text\": \"Texto\", \"created_at\": \"Data de cria√ß√£o\"})"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Data de cria√ß√£o  \\\n",
       "0  Sun Aug 01 17:49:32 +0000 2021   \n",
       "\n",
       "                                               Texto  \n",
       "0  Sociedade\\nH√° mais 28 mortes e 1.513 infec√ß√µes...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data de cria√ß√£o</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 01 17:49:32 +0000 2021</td>\n",
       "      <td>Sociedade\\nH√° mais 28 mortes e 1.513 infec√ß√µes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por fim, adicionamos uma coluna chamada \"Sentimento\", aonde ser√° colocada a anota√ß√£o manual do sentimento de cada um desses tweets, e salvamos o DataFrame em um arquivo Excel, aonde √© mais simples a manipula√ß√£o."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "#11\n",
    "dfTweets.insert(2, \"Sentimento1\", \" \")\n",
    "dfTweets.insert(3, \"Sentimento2\", \" \")\n",
    "dfTweets.insert(4, \"SentimentoFinal\", \" \")\n",
    "dfTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TweetsColetadosCovid.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos dividir e duplicar os datasets bin√°rios!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBinary = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflix.xlsx', index_col=0,  engine='openpyxl') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "newTweets = tweetsToBinary[tweetsToBinary['SentimentoFinal'] != 0]\n",
    "#newTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixBin.xlsx\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos balancear o dataset j√° existente entre neutros, positivos e negativos!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBalance = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTeste.xlsx', index_col=0,  engine='openpyxl')\n",
    "tweetsNeutral = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 0]\n",
    "tweetsPositive = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 1]\n",
    "tweetsNegative = tweetsToBalance[tweetsToBalance['SentimentoFinal'] == 2]\n",
    "\n",
    "print(len(tweetsNeutral))\n",
    "print(len(tweetsPositive))\n",
    "print(len(tweetsNegative))\n",
    "#df.index[[1,3]], inplace=True\n",
    "newTweetNeutral = tweetsNeutral.drop(tweetsNeutral.index[[range(0,41)]])\n",
    "newTweetPositive = tweetsPositive\n",
    "newTweetNegative = tweetsNegative.drop(tweetsNegative.index[[range(0,82)]])\n",
    "print(len(newTweetNeutral))\n",
    "print(len(newTweetPositive))\n",
    "print(len(newTweetNegative))\n",
    "\n",
    "newTweetList = pd.concat([newTweetNeutral, newTweetPositive, newTweetNegative])\n",
    "print(len(newTweetList))\n",
    "# shuffle the DataFrame rows\n",
    "df = newTweetList.sample(frac = 1)\n",
    "df\n",
    "#df.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBalenceada.xlsx\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n",
      "59\n",
      "141\n",
      "59\n",
      "59\n",
      "59\n",
      "177\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:4107: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, iremos balancear o dataset bin√°rio!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "#ler o arquivo\n",
    "tweetsToBinaryBalance = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBalenceada.xlsx', index_col=0,  engine='openpyxl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "newTweets = tweetsToBinaryBalance[tweetsToBinaryBalance['SentimentoFinal'] != 0]\n",
    "#newTweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceado.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A partir daqui, j√° deve ter sido realizada a anota√ß√£o manual dos tweets!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tendo feita a anota√ß√£o manual dos tweets, que no caso desse trabalho foi feito por 3 pessoas, adicionamos a tabela excel em uma variavel chamada tweets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "source": [
    "#12\n",
    "tweets= pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceado.xlsx', index_col=0,  engine='openpyxl') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vemos como ficou nossa tabela.\n",
    "Lembrando que tweets classificados como 0 s√£o negativos, como 1 s√£o positivos e como 2 s√£o neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "source": [
    "#13\n",
    "tweets = tweets.reset_index()\n",
    "tweets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     index                                          full_text  Sentimento1  \\\n",
       "0      195  ü§î N√£o sabia desses dados? Curtiu a informa√ß√£o?...            2   \n",
       "1      294  At√© agora temos no Brasil:\\n\\n-14237078 casos ...            2   \n",
       "2      211  COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO i...            2   \n",
       "3      140  Comando Conjunto Leste (C Cj L), em parceria c...            1   \n",
       "4      194  A se√ß√£o voltada aos povos ind√≠genas do guia Im...            2   \n",
       "..     ...                                                ...          ...   \n",
       "113    206  SAIU! JAILBREAK CHECKRA1N PARA IOS 14.4.2 | FA...            2   \n",
       "114    151  üíâVacina√ß√£o em Maca√© &lt;&lt;\\n\\nFique ligado n...            1   \n",
       "115    200  INSTALOU O iOS 14? SAIBA COMO VOLTAR PARA O iO...            2   \n",
       "116     69  Em Cuba, a vacina √© SOBERANA. At√© o nome √© lin...            1   \n",
       "117     87  Zero Mortes de Covid foi alcan√ßada em Israel ,...            1   \n",
       "\n",
       "     Sentimento2  SentimentoFinal  \n",
       "0              2                2  \n",
       "1              2                2  \n",
       "2              2                2  \n",
       "3              1                1  \n",
       "4              2                2  \n",
       "..           ...              ...  \n",
       "113            2                2  \n",
       "114            2                1  \n",
       "115            2                2  \n",
       "116            1                1  \n",
       "117            1                1  \n",
       "\n",
       "[118 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>ü§î N√£o sabia desses dados? Curtiu a informa√ß√£o?...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294</td>\n",
       "      <td>At√© agora temos no Brasil:\\n\\n-14237078 casos ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO i...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>Comando Conjunto Leste (C Cj L), em parceria c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>A se√ß√£o voltada aos povos ind√≠genas do guia Im...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>206</td>\n",
       "      <td>SAIU! JAILBREAK CHECKRA1N PARA IOS 14.4.2 | FA...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>151</td>\n",
       "      <td>üíâVacina√ß√£o em Maca√© &amp;lt;&amp;lt;\\n\\nFique ligado n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>200</td>\n",
       "      <td>INSTALOU O iOS 14? SAIBA COMO VOLTAR PARA O iO...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>69</td>\n",
       "      <td>Em Cuba, a vacina √© SOBERANA. At√© o nome √© lin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>87</td>\n",
       "      <td>Zero Mortes de Covid foi alcan√ßada em Israel ,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows √ó 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 510
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A seguir, iniciaremos o trabalho de pr√©-processamento dos tweets dos nossos datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### O pr√©-processamento tem como objetivo deixar o texto presente nos tweets mais \"limpo\". Est√° sendo feito com apenas 1 dataset, apenas como exemplo, mas a t√©cnica foi aplicada nos 3 datasets. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos utilizar um tweet como exemplo para que possa ser verificada o resultado de cada uma das tarefas de pr√©-processamento."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "source": [
    "#14\n",
    "exemploPreProcess = (tweets.at[2,'full_text'])\n",
    "print (exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COMO #SINCRONIZAR OS #CONTATOS DO #GOOGLE NO iPhone em 2021 | INFAL√çVEL\n",
      "https://t.co/0c4D9ZKajo\n",
      "\n",
      " #google #CoronaVac #coronavirus #apple #ios #iphone #AppleRetweetBot #vemvacina #bbb21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para a tokeniza√ß√£o dos tweets (separar a frase em pequenos termos que fa√ßam sentido), utilizamos uma biblioteca espec√≠fica para tweets. Ela auxilia na separa√ß√£o de emojis, hashtags, men√ß√µes e outras quest√µes pr√≥prias do Twitter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "source": [
    "#15\n",
    "tweet_tokenize = TweetTokenizer()\n",
    "tweet_tokenize.tokenize(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['COMO',\n",
       " '#SINCRONIZAR',\n",
       " 'OS',\n",
       " '#CONTATOS',\n",
       " 'DO',\n",
       " '#GOOGLE',\n",
       " 'NO',\n",
       " 'iPhone',\n",
       " 'em',\n",
       " '2021',\n",
       " '|',\n",
       " 'INFAL√çVEL',\n",
       " 'https://t.co/0c4D9ZKajo',\n",
       " '#google',\n",
       " '#CoronaVac',\n",
       " '#coronavirus',\n",
       " '#apple',\n",
       " '#ios',\n",
       " '#iphone',\n",
       " '#AppleRetweetBot',\n",
       " '#vemvacina',\n",
       " '#bbb21']"
      ]
     },
     "metadata": {},
     "execution_count": 512
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A seguir, baixamos uma base de \"stopwords\" em portugu√™s. Stopwords s√£o palavras que n√£o agregam sentido ao texto. Artigos e preposi√ß√µes s√£o exemplos de stopwords."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "source": [
    "#16\n",
    "try:\n",
    "     _create_unverified_https_context =     ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "     pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download('stopwords')\n",
    "def RemoveStopWords(tweet):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    textInWords = []\n",
    "    for word in tweet.lower().split():\n",
    "        if (word not in stopwords) and (word.isdigit() == False): \n",
    "            textInWords.append(word)\n",
    "\n",
    "    res = ' '.join(map(str, textInWords))\n",
    "    return res"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver abaixo como fica o tweet ap√≥s a remo√ß√£o de suas stopwords."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "source": [
    "#17\n",
    "RemoveStopWords(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'#sincronizar #contatos #google iphone | infal√≠vel https://t.co/0c4d9zkajo #google #coronavac #coronavirus #apple #ios #iphone #appleretweetbot #vemvacina #bbb21'"
      ]
     },
     "metadata": {},
     "execution_count": 514
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para fazer a stemiza√ß√£o de cada tweet (deixar apenas a raiz(radical) de cada termo), utilizamos uma biblioteca pr√≥pria que nos ajuda a fazer isso. Essa bibloteca √© espec√≠fica para portugu√™s. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "source": [
    "#18\n",
    "nltk.download('rslp')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 515
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "source": [
    "#19\n",
    "#stemmer = nltk.stem.porter.PorterStemmer()\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tweet):\n",
    "    textInWords = []\n",
    "    for word in tweet.lower().split():\n",
    "        textInWords.append(stemmer.stem(word))\n",
    "    res = ' '.join(map(str, textInWords))\n",
    "    return res\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver abaixo como fica o tweet ap√≥s a sua stemiza√ß√£o."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "source": [
    "#20\n",
    "stem_tokens(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'com #sincron os #contat do #googl no iphon em 2021 | infal https://t.co/0c4d9zkaj #googl #coronavac #coronaviru #appl #io #iphon #appleretweetbot #vemvacin #bbb21'"
      ]
     },
     "metadata": {},
     "execution_count": 517
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, temos uma fun√ß√£o de \"limpeza\". Nela, s√£o exclu√≠das quaisquer caracteres que n√£o s√£o letras. Tamb√©m s√£o exclu√≠dos links, hashtags e emojis. Todas as letras s√£o passadas para min√∫sculo. Al√©m disso, s√£o exclu√≠dos d√≠gitos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "source": [
    "#21\n",
    "def Limpa_dados(tweet): ##M MUDAR NOME DESSA FUNCAO\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets E ACENTOS\n",
    "    tweet = unidecode(re.sub(r\"http\\S+\", \"\", tweet).lower().replace('.','')\n",
    "                      .replace(';','').replace('+','').replace(']','').replace('[','').replace('\\'','').replace(';','').replace('%','').replace('-',' ').replace(',',' ')\n",
    "                      .replace('\\n','').replace('\\\"','').replace(')','').replace('(','').replace('$','').replace('?','')\n",
    "                      .replace('_','').replace(':','').replace('!','').replace('|','').replace('/','').replace(')',''))\n",
    "    tweet = unidecode(re.sub(r\"@[A-Za-z0-9]+\", \"\", tweet))\n",
    "    tweet = unidecode(re.sub(r\"\\#[A-Za-z0-9]+\", \"\", tweet))\n",
    "    \n",
    "    tweet = unidecode(re.sub(r\"[0-9]+[A-Za-z0-9]+\", \"\", tweet)) #Remove digitos\n",
    "    tweet = tweet.replace('  ', ' ') #Corrige espa√ßos feitos a mais.\n",
    "    tweet = tweet.replace('[?]', ' ') #Corrige outros errinhos.\n",
    "    return (tweet)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vemos o tweets ap√≥s a sua \"limpeza\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "source": [
    "#22\n",
    "Limpa_dados(exemploPreProcess)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'como os do no iphone em  infalivel     '"
      ]
     },
     "metadata": {},
     "execution_count": 519
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por fim, executamos as 3 fun√ß√µes de pr√©-processamento e adicionamos a uma nova tabela Excel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "source": [
    "#23\n",
    "#PreProcessa todos os tweets:\n",
    "\n",
    "qtdTweets = len(tweets)\n",
    "for tweet in range (qtdTweets):\n",
    "    tweets.at[tweet, 'full_text'] =  Limpa_dados(str(tweets.at[tweet, 'full_text']))\n",
    "    tweets.at[tweet, 'full_text'] =  RemoveStopWords(str(tweets.at[tweet, 'full_text']))\n",
    "    tweets.at[tweet, 'full_text'] =  stem_tokens(str(tweets.at[tweet, 'full_text']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "source": [
    "#24\n",
    "#tweets.to_excel(\"/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinBalanceadoPreProcessados.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Come√ßaremos ent√£o o processo de treinamento por parte dos algoritmos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primeiramente, pegamos os dados de treinamento e teste. Aqui estaremos treinando o algoritmo com os dados de covid (700 tweets) e testando com os dados de covid (300 tweets). Os dados vem de tabelas diferentes e s√£o diferentes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "source": [
    "dadosTreino = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTreinoPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "dadosTeste = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTestePreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "source": [
    "dadosTreino.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  notic hor vai vacin nest feri enta fiqu atent ...            2   \n",
       "1           1  import pal expliqu importanc med prevenca cont...            2   \n",
       "2           2  veicul cont sistem mens som informaco utel pop...            2   \n",
       "3           3  beij temp cris sar arapiun edn arapiun devid v...            2   \n",
       "4           4  despach intim presid jair bolsonar ministr sau...            2   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            2                2  \n",
       "1            2                2  \n",
       "2            2                2  \n",
       "3            2                2  \n",
       "4            2                2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>notic hor vai vacin nest feri enta fiqu atent ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>import pal expliqu importanc med prevenca cont...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>veicul cont sistem mens som informaco utel pop...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>beij temp cris sar arapiun edn arapiun devid v...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>despach intim presid jair bolsonar ministr sau...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 523
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "source": [
    "dadosTeste.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  assum risc tom morr pesquis demonstr cloroquin...            0   \n",
       "1           1  ind imag hospit gtb nov delh vari paci esta es...            0   \n",
       "2           2  brasil numer suspeit cas confirm numer mort re...            2   \n",
       "3           3  boletim check up saudeol vej aco melhor saud d...            2   \n",
       "4           4    catorz est distrit feder mant ocupaca util acim            0   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            0                0  \n",
       "1            2                0  \n",
       "2            2                2  \n",
       "3            2                2  \n",
       "4            0                0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>assum risc tom morr pesquis demonstr cloroquin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ind imag hospit gtb nov delh vari paci esta es...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brasil numer suspeit cas confirm numer mort re...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>boletim check up saudeol vej aco melhor saud d...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>catorz est distrit feder mant ocupaca util acim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 524
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos pegar os textos dos tweets de treinamento e teste e seus respectivos sentimentos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "source": [
    "tweetsParaTreino = dadosTreino['full_text'].values\n",
    "classesParaTreino = dadosTreino['SentimentoFinal'].values\n",
    "tweetsParaTeste = dadosTeste['full_text'].values\n",
    "classesParaTeste = dadosTeste['SentimentoFinal'].values\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos a t√©cnica Holdout, separando os dados em 70% para treinamento e 30% para teste."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "source": [
    "qtdTweetsTreino = len(dadosTreino)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 526
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "source": [
    "qtdTweetsTeste = len(dadosTeste)\n",
    "qtdTweetsTeste"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 527
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqui, instanciamos o vetorizador dos tweets. Ele √© respons√°vel pela transforma√ß√£o dos dados textuais em um formato que o algoritmo entenda. √â utilizada a t√©cnica Bag Of Words, aonde as palavras viram colunas em uma tabela e cada tweet ter√° uma representa√ß√£o de 0's e 1's. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "source": [
    "# Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, vetorizamos os dados de treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "source": [
    "vect_tweetsTreino = vectorizer.fit_transform(tweetsParaTreino) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, faremos o treinamento do algoritmo. Utilizamos o algoritmo Multinomial Naive Bayes, o SVM."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "source": [
    "classificador = MultinomialNB()\n",
    "classificadorBerno = BernoulliNB()\n",
    "classificadorComplement = ComplementNB()\n",
    "classificador.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "classificadorBerno.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "classificadorComplement.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "\n",
    "classificadorSVM = svm.SVC(kernel='linear')\n",
    "classificadorSVM.fit(vect_tweetsTreino, classesParaTreino)\n",
    "\n",
    "classificadorLR = LogisticRegression(random_state=0).fit(vect_tweetsTreino, classesParaTreino)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "J√° tendo o algoritmo sido treinado, faremos a vetoriza√ß√£o dos dados de teste."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "source": [
    "vect_tweetsTeste = vectorizer.transform(tweetsParaTeste) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, fazemos a predi√ß√£o dos dados de teste por parte do algoritmo j√° treinado."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "source": [
    "result = classificador.predict(vect_tweetsTeste)\n",
    "resultBerno = classificadorBerno.predict(vect_tweetsTeste)\n",
    "resultComplement = classificadorComplement.predict(vect_tweetsTeste)\n",
    "resultSVM = classificadorSVM.predict(vect_tweetsTeste)\n",
    "resultLR = classificadorLR.predict(vect_tweetsTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agora j√° possu√≠mos o algoritmo treinado e os dados para verificar o resultado nos testes. Vamos prosseguir vendo o resultado das m√©tricas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos ver a acur√°cia primeiramente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "source": [
    "acc = accuracy_score(classesParaTeste, result) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTeste, resultSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTeste, resultLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTeste, resultBerno) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTeste, resultComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63.0% \n",
      "60.33% \n",
      "63.67% \n",
      "63.67% \n",
      "63.67% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos verificar a matriz de confus√£o agora. Ela tem o objetivo de ver em que classes o algoritmo conseguiu classificar melhor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "source": [
    "print (pd.crosstab(classesParaTeste, result, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito    0   1    2  All\n",
      "Real                      \n",
      "0         83   6   11  100\n",
      "1         20  22   17   59\n",
      "2         41  16   84  141\n",
      "All      144  44  112  300\n",
      "Predito   0  1    2  All\n",
      "Real                    \n",
      "0        42  2   56  100\n",
      "1        13  2   44   59\n",
      "2        10  1  130  141\n",
      "All      65  5  230  300\n",
      "Predito    0   1    2  All\n",
      "Real                      \n",
      "0         76   8   16  100\n",
      "1         16  31   12   59\n",
      "2         42  19   80  141\n",
      "All      134  58  108  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos verificar, por fim, as outras m√©tricas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "source": [
    "print(classification_report(classesParaTeste, result, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultLR, labels = [0,1,2]))\n",
    "\n",
    "print(classification_report(classesParaTeste, resultBerno, labels = [0,1,2]))\n",
    "\n",
    "print(classification_report(classesParaTeste, resultComplement, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68       100\n",
      "           1       0.50      0.37      0.43        59\n",
      "           2       0.75      0.60      0.66       141\n",
      "\n",
      "    accuracy                           0.63       300\n",
      "   macro avg       0.61      0.60      0.59       300\n",
      "weighted avg       0.64      0.63      0.62       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.42      0.51       100\n",
      "           1       0.40      0.03      0.06        59\n",
      "           2       0.57      0.92      0.70       141\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.54      0.46      0.42       300\n",
      "weighted avg       0.56      0.58      0.51       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.76      0.65       100\n",
      "           1       0.53      0.53      0.53        59\n",
      "           2       0.74      0.57      0.64       141\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.61      0.62      0.61       300\n",
      "weighted avg       0.64      0.62      0.62       300\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agora, faremos o treinamento com os dados da tabela de assuntos diversos (700 tweets). A tabela de teste segue sendo a mesma."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esse processo √© semelhante ao feito anteriormente, ent√£o n√£o h√° necessidade de explicar cada etapa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "source": [
    "dadosTreinoDiversos = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosPreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "source": [
    "dadosTreinoDiversos.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          full_text  Sentimento1  \\\n",
       "0           0  ant malest coa falt dialog med xunt propux abr...            0   \n",
       "1           1                       pra gast pod gast pouc acess            2   \n",
       "2           2              oposica reform tribut desconhec lobby            0   \n",
       "3           3                  importanc poupanc composica setor            1   \n",
       "4           4                                  \"pib governo\" err            0   \n",
       "\n",
       "   Sentimento2  SentimentoFinal  \n",
       "0            0                0  \n",
       "1            2                2  \n",
       "2            2                2  \n",
       "3            1                1  \n",
       "4            2                0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ant malest coa falt dialog med xunt propux abr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pra gast pod gast pouc acess</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>oposica reform tribut desconhec lobby</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>importanc poupanc composica setor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"pib governo\" err</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 537
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "source": [
    "tweetsParaTreinoDiversos = dadosTreinoDiversos['full_text'].values\n",
    "classesParaTreinoDiversos = dadosTreinoDiversos['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "source": [
    "qtdTweetsTreino = len(dadosTreinoDiversos)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 539
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "source": [
    "vect_tweetsTreinoDiversos = vectorizer.fit_transform(tweetsParaTreinoDiversos)  #treina com diversos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "source": [
    "classificadorDiversos = MultinomialNB()\n",
    "classificadorDiversos.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorDiversosBerno = BernoulliNB()\n",
    "classificadorDiversosBerno.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorDiversosComplement = ComplementNB()\n",
    "classificadorDiversosComplement.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos) \n",
    "\n",
    "classificadorSVMDiv = svm.SVC(kernel='linear')\n",
    "classificadorSVMDiv.fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos)\n",
    "\n",
    "classificadorLRDiv = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiversos, classesParaTreinoDiversos)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "source": [
    "vect_tweetsTeste = vectorizer.transform(tweetsParaTeste) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "source": [
    "resultDiversos = classificadorDiversos.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosBerno = classificadorDiversosBerno.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosComplement = classificadorDiversosComplement.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosSVM = classificadorSVMDiv.predict(vect_tweetsTeste)\n",
    "\n",
    "resultDiversosLR = classificadorLRDiv.predict(vect_tweetsTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "source": [
    "acc = accuracy_score(classesParaTeste, resultDiversos) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTeste, resultDiversosSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTeste, resultDiversosLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTeste, resultDiversosBerno) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTeste, resultDiversosComplement) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "55.0% \n",
      "61.67% \n",
      "58.0% \n",
      "55.0% \n",
      "55.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "source": [
    "print (pd.crosstab(classesParaTeste, resultDiversos, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultDiversosSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTeste, resultDiversosLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultDiversosBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultDiversosComplement, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        40  17   43  100\n",
      "1         5  32   22   59\n",
      "2        19  29   93  141\n",
      "All      64  78  158  300\n",
      "Predito  0   1    2  All\n",
      "Real                    \n",
      "0        5   3   92  100\n",
      "1        0   6   53   59\n",
      "2        0   3  138  141\n",
      "All      5  12  283  300\n",
      "Predito   0    1    2  All\n",
      "Real                      \n",
      "0        52   25   23  100\n",
      "1         6   39   14   59\n",
      "2        31   40   70  141\n",
      "All      89  104  107  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "source": [
    "print(classification_report(classesParaTeste, resultDiversos, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTeste, resultDiversosBerno, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTeste, resultDiversosComplement, labels = [0,1,2]))\n",
    "\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultDiversosSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTeste, resultDiversosLR, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.49       100\n",
      "           1       0.41      0.54      0.47        59\n",
      "           2       0.59      0.66      0.62       141\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.54      0.53      0.53       300\n",
      "weighted avg       0.57      0.55      0.55       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10       100\n",
      "           1       0.50      0.10      0.17        59\n",
      "           2       0.49      0.98      0.65       141\n",
      "\n",
      "    accuracy                           0.50       300\n",
      "   macro avg       0.66      0.38      0.31       300\n",
      "weighted avg       0.66      0.50      0.37       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       100\n",
      "           1       0.38      0.66      0.48        59\n",
      "           2       0.65      0.50      0.56       141\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.54      0.56      0.53       300\n",
      "weighted avg       0.58      0.54      0.54       300\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agora faremos a classifica√ß√£o em tabelas bin√°rias, aonde h√° apenas as classes positiva e negativa (1 e 0)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para tal, foram feitas c√≥pias dos 3 datasets e exclu√≠dos os tweets neutros nessas c√≥pias. Assim, faremos o treinamento e teste novamente nestes datasets.\n",
    "Este processo j√° foi explicado anteriormente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "source": [
    "dadosTreinoBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTreinoBinPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "dadosTesteBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaCovidTesteBinPreProcessados.xlsx',engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "source": [
    "len(dadosTreinoBin)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "metadata": {},
     "execution_count": 564
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "source": [
    "len(dadosTesteBin)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 565
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "source": [
    "tweetsParaTreinoBin = dadosTreinoBin['full_text'].values\n",
    "classesParaTreinoBin = dadosTreinoBin['SentimentoFinal'].values\n",
    "tweetsParaTesteBin = dadosTesteBin['full_text'].values\n",
    "classesParaTesteBin = dadosTesteBin['SentimentoFinal'].values\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "source": [
    "# Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "source": [
    "vect_tweetsTreinoBin = vectorizer.fit_transform(tweetsParaTreinoBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "source": [
    "classificadorBin = MultinomialNB()\n",
    "classificadorBin.fit(vect_tweetsTreinoBin, classesParaTreinoBin)\n",
    "\n",
    "classificadorBinBerno = BernoulliNB()\n",
    "classificadorBinBerno.fit(vect_tweetsTreinoBin, classesParaTreinoBin) \n",
    "\n",
    "classificadorBinComplement = ComplementNB()\n",
    "classificadorBinComplement.fit(vect_tweetsTreinoBin, classesParaTreinoBin) \n",
    "\n",
    "classificadorSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorSVMBin.fit(vect_tweetsTreinoBin, classesParaTreinoBin)\n",
    "\n",
    "classificadorLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoBin, classesParaTreinoBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "source": [
    "vect_tweetsTesteBin = vectorizer.transform(tweetsParaTesteBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "source": [
    "resultBin = classificadorBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinBerno = classificadorBinBerno.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinComplement = classificadorBinComplement.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinSVM = classificadorSVMBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultBinLR = classificadorLRBin.predict(vect_tweetsTesteBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "source": [
    "acc = accuracy_score(classesParaTesteBin, resultBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteBin, resultBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteBin, resultBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteBin, resultBinBerno) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteBin, resultBinComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74.5% \n",
      "78.0% \n",
      "80.0% \n",
      "78.0% \n",
      "80.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "source": [
    "print (pd.crosstab(classesParaTesteBin, resultBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultBinLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultBinBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultBinComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        38   21   59\n",
      "2        30  111  141\n",
      "All      68  132  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        10   49   59\n",
      "2         5  136  141\n",
      "All      15  185  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        42   17   59\n",
      "2        43   98  141\n",
      "All      85  115  200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "source": [
    "print(classification_report(classesParaTesteBin, resultBin, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultBinSVM, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultBinLR, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultBinBerno, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultBinComplement, labels = [0,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.56      0.64      0.60        59\n",
      "\n",
      "   micro avg       0.56      0.64      0.60        59\n",
      "   macro avg       0.28      0.32      0.30        59\n",
      "weighted avg       0.56      0.64      0.60        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.67      0.17      0.27        59\n",
      "\n",
      "   micro avg       0.67      0.17      0.27        59\n",
      "   macro avg       0.33      0.08      0.14        59\n",
      "weighted avg       0.67      0.17      0.27        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.49      0.71      0.58        59\n",
      "\n",
      "   micro avg       0.49      0.71      0.58        59\n",
      "   macro avg       0.25      0.36      0.29        59\n",
      "weighted avg       0.49      0.71      0.58        59\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Agora faremos o treinamento com o dataset de assuntos diversos sem os tweets neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('TabelaDiversosBinPreProcessados.xlsx', engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "source": [
    "tweetsParaTreinoDiversosBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDiversosBin = dadosTreinoDiversosBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "source": [
    "qtdTweetsTreinoBin = len(dadosTreinoDiversosBin)\n",
    "qtdTweetsTreinoBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "metadata": {},
     "execution_count": 584
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "source": [
    "vect_tweetsTreinoDiversosBin = vectorizer.fit_transform(tweetsParaTreinoDiversosBin)  #treina com diversos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "source": [
    "classificadorDiversosBin = MultinomialNB()\n",
    "classificadorDiversosBin.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorDiversosBinBerno = BernoulliNB()\n",
    "classificadorDiversosBinBerno.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin) \n",
    "\n",
    "classificadorDiversosBinComplement = ComplementNB()\n",
    "classificadorDiversosBinComplement.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin) \n",
    "\n",
    "classificadorDiversosSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorDiversosSVMBin.fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorDiversosLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiversosBin, classesParaTreinoDiversosBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "source": [
    "vect_tweetsTesteBin = vectorizer.transform(tweetsParaTesteBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "source": [
    "resultDiversosBin = classificadorDiversosBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinBerno = classificadorDiversosBinBerno.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinComplement = classificadorDiversosBinComplement.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinSVM = classificadorDiversosSVMBin.predict(vect_tweetsTesteBin)\n",
    "\n",
    "resultDiversosBinLR = classificadorDiversosLRBin.predict(vect_tweetsTesteBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "source": [
    "acc = accuracy_score(classesParaTesteBin, resultDiversosBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteBin, resultDiversosBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteBin, resultDiversosBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteBin, resultDiversosBinBerno) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteBin, resultDiversosBinComplement) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69.0% \n",
      "80.0% \n",
      "78.5% \n",
      "80.0% \n",
      "78.5% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "source": [
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultDiversosBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteBin, resultDiversosBinLR, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBinBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteBin, resultDiversosBinComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        36   23   59\n",
      "2        39  102  141\n",
      "All      75  125  200\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1         7   52   59\n",
      "2         5  136  141\n",
      "All      12  188  200\n",
      "Predito    1   2  All\n",
      "Real                 \n",
      "1         45  14   59\n",
      "2         62  79  141\n",
      "All      107  93  200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "source": [
    "print(classification_report(classesParaTesteBin, resultDiversosBin, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultDiversosBinSVM, labels = [0,1]))\n",
    "\n",
    "#print(classification_report(classesParaTesteBin, resultDiversosBinLR, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultDiversosBinBerno, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteBin, resultDiversosBinComplement, labels = [0,1]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.48      0.61      0.54        59\n",
      "\n",
      "   micro avg       0.48      0.61      0.54        59\n",
      "   macro avg       0.24      0.31      0.27        59\n",
      "weighted avg       0.48      0.61      0.54        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.58      0.12      0.20        59\n",
      "\n",
      "   micro avg       0.58      0.12      0.20        59\n",
      "   macro avg       0.29      0.06      0.10        59\n",
      "weighted avg       0.58      0.12      0.20        59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.42      0.76      0.54        59\n",
      "\n",
      "   micro avg       0.42      0.76      0.54        59\n",
      "   macro avg       0.21      0.38      0.27        59\n",
      "weighted avg       0.42      0.76      0.54        59\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teste cruzado com  #netflix bin√°rio"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosBinPreProcessados.xlsx',  engine='openpyxl').fillna(' ')\n",
    "dadosTesteNetflixBin = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixBinPreProcessados.xlsx',  engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "source": [
    "tweetsParaTreinoDivBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDivBin = dadosTreinoDiversosBin['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflixBin = dadosTesteNetflixBin['full_text'].values\n",
    "classesParaTesteNetflixBin = dadosTesteNetflixBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "source": [
    "qtdTweetsTreinoBin = len(dadosTreinoDiversosBin)\n",
    "qtdTweetsTreinoBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "metadata": {},
     "execution_count": 680
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "source": [
    "qtdTweetsTesteBin = len(dadosTesteNetflixBin)\n",
    "qtdTweetsTesteBin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "metadata": {},
     "execution_count": 681
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "source": [
    "# Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto:\n",
    "tweet_tokenizer_bin = TweetTokenizer() \n",
    "vectorizerBin = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer_bin.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "source": [
    "vect_tweetsTreinoDivBin = vectorizerBin.fit_transform(tweetsParaTreinoDivBin)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "source": [
    "classificadorValidBin = MultinomialNB()\n",
    "classificadorValidBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)\n",
    "\n",
    "classificadorValidBernoBin = BernoulliNB()\n",
    "classificadorValidBernoBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin) \n",
    "\n",
    "classificadorValidComplementBin = ComplementNB()\n",
    "classificadorValidComplementBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin) \n",
    "\n",
    "classificadorValidSVMBin = svm.SVC(kernel='linear')\n",
    "classificadorValidSVMBin.fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)\n",
    "\n",
    "classificadorValidLRBin = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDivBin, classesParaTreinoDivBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "source": [
    "vect_tweetsTesteNetflixBin = vectorizerBin.transform(tweetsParaTesteNetflixBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "source": [
    "resultValidBin = classificadorValidBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBernoBin = classificadorValidBernoBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidComplementBin = classificadorValidComplementBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidSVMBin = classificadorValidSVMBin.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidLRBin = classificadorValidLRBin.predict(vect_tweetsTesteNetflixBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflixBin, resultValidBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflixBin, resultValidSVMBin) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflixBin, resultValidLRBin) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteNetflixBin, resultValidBernoBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteNetflixBin, resultValidComplementBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "66.95% \n",
      "67.36% \n",
      "70.71% \n",
      "66.95% \n",
      "66.95% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBernoBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidComplementBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflixBin, resultValidSVMBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflixBin, resultValidLRBin, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        13   53   66\n",
      "2        26  147  173\n",
      "All      39  200  239\n",
      "Predito  1    2  All\n",
      "Real                \n",
      "1        2   64   66\n",
      "2        1  172  173\n",
      "All      3  236  239\n",
      "Predito   1    2  All\n",
      "Real                 \n",
      "1        23   43   66\n",
      "2        50  123  173\n",
      "All      73  166  239\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Por fim, vamos validar os resultados realizando o treinamento com os tweets de assuntos diversos e o teste com os tweets #netflix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esta etapa de treinamento/teste √© como as anteriores, logo, n√£o h√° necessidade de explicar cada passo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "source": [
    "dadosTreinoDiversos = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaDiversosPreProcessados.xlsx',  engine='openpyxl').fillna(' ')\n",
    "dadosTesteNetflix = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/TabelaNetflixPreProcessados.xlsx',  engine='openpyxl').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "source": [
    "tweetsParaTreinoDiv = dadosTreinoDiversos['full_text'].values\n",
    "classesParaTreinoDiv = dadosTreinoDiversos['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflix = dadosTesteNetflix['full_text'].values\n",
    "classesParaTesteNetflix = dadosTesteNetflix['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "source": [
    "qtdTweetsTreino = len(dadosTreinoDiversos)\n",
    "qtdTweetsTreino"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "metadata": {},
     "execution_count": 616
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "source": [
    "qtdTweetsTeste = len(dadosTesteNetflix)\n",
    "qtdTweetsTeste"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 617
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "source": [
    "# Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "source": [
    "vect_tweetsTreinoDiv = vectorizer.fit_transform(tweetsParaTreinoDiv)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "source": [
    "classificadorValid = MultinomialNB()\n",
    "classificadorValid.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)\n",
    "\n",
    "classificadorValidBerno = BernoulliNB()\n",
    "classificadorValidBerno.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv) \n",
    "\n",
    "classificadorValidComplement = ComplementNB()\n",
    "classificadorValidComplement.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv) \n",
    "\n",
    "classificadorValidSVM = svm.SVC(kernel='linear')\n",
    "classificadorValidSVM.fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)\n",
    "\n",
    "classificadorValidLR = LogisticRegression(random_state=0).fit(vect_tweetsTreinoDiv, classesParaTreinoDiv)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "source": [
    "vect_tweetsTesteNetflix = vectorizer.transform(tweetsParaTesteNetflix) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "source": [
    "resultValid = classificadorValid.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidBerno = classificadorValidBerno.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidComplement = classificadorValidComplement.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidSVM = classificadorValidSVM.predict(vect_tweetsTesteNetflix)\n",
    "\n",
    "resultValidLR = classificadorValidLR.predict(vect_tweetsTesteNetflix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflix, resultValid) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflix, resultValidSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflix, resultValidLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))\n",
    "\n",
    "acc4 = accuracy_score(classesParaTesteNetflix, resultValidBerno) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc5 = accuracy_score(classesParaTesteNetflix, resultValidComplement) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "54.0% \n",
      "56.33% \n",
      "57.33% \n",
      "54.0% \n",
      "54.0% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflix, resultValid, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflix, resultValidBerno, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflix, resultValidComplement, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflix, resultValidSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteNetflix, resultValidLR, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        15   5   41   61\n",
      "1         6   9   51   66\n",
      "2        10  25  138  173\n",
      "All      31  39  230  300\n",
      "Predito  1    2  All\n",
      "Real                \n",
      "0        0   61   61\n",
      "1        2   64   66\n",
      "2        0  173  173\n",
      "All      2  298  300\n",
      "Predito   0   1    2  All\n",
      "Real                     \n",
      "0        25   8   28   61\n",
      "1        20  17   29   66\n",
      "2        32  37  104  173\n",
      "All      77  62  161  300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "source": [
    "print(classification_report(classesParaTesteNetflix, resultValid, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteNetflix, resultValidBerno, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteNetflix, resultValidComplement, labels = [0,1,2]))\n",
    "\n",
    "\n",
    "#print(classification_report(classesParaTesteNetflix, resultValidSVM, labels = [0,1,2]))\n",
    "\n",
    "#print(classification_report(classesParaTesteNetflix, resultValidLR, labels = [0,1,2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.25      0.33        61\n",
      "           1       0.23      0.14      0.17        66\n",
      "           2       0.60      0.80      0.68       173\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.44      0.39      0.39       300\n",
      "weighted avg       0.50      0.54      0.50       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        61\n",
      "           1       1.00      0.03      0.06        66\n",
      "           2       0.58      1.00      0.73       173\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.53      0.34      0.26       300\n",
      "weighted avg       0.55      0.58      0.44       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.41      0.36        61\n",
      "           1       0.27      0.26      0.27        66\n",
      "           2       0.65      0.60      0.62       173\n",
      "\n",
      "    accuracy                           0.49       300\n",
      "   macro avg       0.41      0.42      0.42       300\n",
      "weighted avg       0.50      0.49      0.49       300\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, o treinamento/teste aonde sem tweets neutros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "dadosTreinoDiversosBin = pd.read_excel('TabelaDiversosPreProcessadosBin.xlsx').fillna(' ')\n",
    "dadosTesteNetflixBin = pd.read_excel('TabelaNetflixPreProcessadosBin.xlsx').fillna(' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "tweetsParaTreinoDiversosBin = dadosTreinoDiversosBin['full_text'].values\n",
    "classesParaTreinoDiversosBin = dadosTreinoDiversosBin['SentimentoFinal'].values\n",
    "tweetsParaTesteNetflixBin = dadosTesteNetflixBin['full_text'].values\n",
    "classesParaTesteNetflixBin = dadosTesteNetflixBin['SentimentoFinal'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "vect_tweetsTreinoBin = vectorizer.fit_transform(tweetsParaTreinoDiversosBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "classificadorBinValid = MultinomialNB()\n",
    "classificadorBinValid.fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorBinValidSVM = svm.SVC(kernel='linear')\n",
    "classificadorBinValidSVM.fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)\n",
    "\n",
    "classificadorBinValidLR = LogisticRegression(random_state=0).fit(vect_tweetsTreinoBin, classesParaTreinoDiversosBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "vect_tweetsTesteNetflixBin = vectorizer.transform(tweetsParaTesteNetflixBin) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "resultValidBin = classificadorBinValid.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBinSVM = classificadorBinValidSVM.predict(vect_tweetsTesteNetflixBin)\n",
    "\n",
    "resultValidBinLR = classificadorBinValidLR.predict(vect_tweetsTesteNetflixBin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "acc = accuracy_score(classesParaTesteNetflixBin, resultValidBin) * 100\n",
    "print(\"{}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteNetflixBin, resultValidBinSVM) * 100\n",
    "print(\"{}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteNetflixBin, resultValidBinLR) * 100\n",
    "print(\"{}{} \".format(acc3.round(2), \"%\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68.5% \n",
      "65.35% \n",
      "66.14% \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBin, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBinSVM, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteNetflixBin, resultValidBinLR, rownames=['Real'], colnames=['Predito'], margins=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predito   0   1  All\n",
      "Real                \n",
      "0        44  18   62\n",
      "1        22  43   65\n",
      "All      66  61  127\n",
      "Predito   0   1  All\n",
      "Real                \n",
      "0        35  27   62\n",
      "1        17  48   65\n",
      "All      52  75  127\n",
      "Predito   0   1  All\n",
      "Real                \n",
      "0        33  29   62\n",
      "1        14  51   65\n",
      "All      47  80  127\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "print(classification_report(classesParaTesteNetflixBin, resultValidBin, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteNetflixBin, resultValidBinSVM, labels = [0,1]))\n",
    "\n",
    "print(classification_report(classesParaTesteNetflixBin, resultValidBinLR, labels = [0,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69        62\n",
      "          1       0.70      0.66      0.68        65\n",
      "\n",
      "avg / total       0.69      0.69      0.68       127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.56      0.61        62\n",
      "          1       0.64      0.74      0.69        65\n",
      "\n",
      "avg / total       0.66      0.65      0.65       127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.53      0.61        62\n",
      "          1       0.64      0.78      0.70        65\n",
      "\n",
      "avg / total       0.67      0.66      0.66       127\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "###### Obrigado por olhar o meu notebook! Fique livre para copi√°-lo, altera-lo e utiliza-lo em seus estudos/projetos "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}