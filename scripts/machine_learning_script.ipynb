{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook da Integradora 4\n",
    "## Aluno: Gustavo Duarte\n",
    "## Orientadora: Isabel H. Manssour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, os imports necessário para a realização de todo o notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: click in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: unidecode in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tweepy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from scikit-learn->sklearn) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: xlrd in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ssl\n",
      "  Using cached ssl-1.16.tar.gz (33 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-sab2n2eh/ssl/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-sab2n2eh/ssl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-pip-egg-info-o4dhwkll\n",
      "         cwd: /private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-sab2n2eh/ssl/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/wx/c047tw591yz4cytxbj_26lv40000gp/T/pip-install-sab2n2eh/ssl/setup.py\", line 33\n",
      "        print 'looking for', f\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('looking for', f)?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: imblearn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/gustavoduarte/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn->imblearn) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: toolz in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.11.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/gustavoduarte/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install unidecode\n",
    "!{sys.executable} -m pip install tweepy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install ssl\n",
    "!{sys.executable} -m pip install imblearn\n",
    "!{sys.executable} -m pip install toolz\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import toolz as fp\n",
    "#import nltk\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ssl\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "     _create_unverified_https_context =     ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "     pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download('stopwords')\n",
    "nltk.download('stopwords');\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Começaremos então o processo de treinamento por parte dos algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldataset = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/tweets_classificados/Tweet28000processado.xlsx', engine='openpyxl').fillna(' ')\n",
    "#alldataset = alldataset.reset_index()\n",
    "alldataset df_final.drop(df_final[(df_final['Coluna 2'] < minimo) &\n",
    "                              (df_final['Coluna 4'] < minimo) &\n",
    "                              ((df_final['Coluna 1'] + df_final['Coluna 3']) > valor)])\n",
    "alldataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alldataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dadosTreino = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/dados_processados/7030geral/Tweets70TodosSemThiagoOvitPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "#dadosTeste = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/dados_processados/7030geral/Tweets30TodosSemThiagoOvitPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "# Usamos o Undersampling tecnica onde reduzimos a classe mais alta para equilibrar o dataset\n",
    "dadosTreinoGeral =  pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/tweets_classificados/nosso_sem_thiago_sem_hash_processado.xlsx', engine='openpyxl').fillna(' ')\n",
    "#dados\n",
    "dadosTreinoGeral['SentimentoFinal'].replace(' ', np.nan, inplace=True)\n",
    "#dadosTreinoGeral['SentimentoFinal'].astype('int')\n",
    "dadosTreinoGeral.dropna(subset=['SentimentoFinal'], inplace=True)\n",
    "dadosTesteGeral = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/tweets_classificados/covidtesteprocessado.xlsx', engine='openpyxl').fillna(' ')#alldataset.iloc[1960:2800]#pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/dados_processados/dados_separados_thiago_gustavo/TweetsTreino30OversimpleTesteIndividualPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTreinoGeral['SentimentoFinal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizerGeral = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)\n",
    "#vectorizer = TfidfVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsParaTreinoGeral = dadosTreinoGeral['full_text'].values\n",
    "classesParaTreinoGeral = dadosTreinoGeral['SentimentoFinal'].values\n",
    "#classesParaTreinoGeral = classesParaTreinoGeral.astype('int')\n",
    "tweetsParaTesteGeral = dadosTesteGeral['full_text'].values\n",
    "classesParaTesteGeral = dadosTesteGeral['SentimentoFinal'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "476\n",
      "127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosPositivoTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] == 1]\n",
    "dadosPositivoTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] == 1]\n",
    "dadosNeutroTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] == 0]\n",
    "dadosNeutroTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] == 0]\n",
    "dadosNegativoTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] == 2]\n",
    "dadosNegativoTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] == 2]\n",
    "\n",
    "#AlldatasetNew70 = pd.concat([allDataPositivosG70,allDataNegativosG70,allDataNeutroG70])\n",
    "print(len(dadosPositivoTreino))\n",
    "print(len(dadosNeutroTreino))\n",
    "print(len(dadosNegativoTreino))\n",
    "todosTreino = pd.concat([dadosPositivoTreino,dadosNeutroTreino,dadosNegativoTreino])\n",
    "todosTeste = pd.concat([dadosPositivoTeste,dadosNeutroTeste,dadosNegativoTeste])\n",
    "len(todosTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTreinoGeral = vectorizerGeral.fit_transform(tweetsParaTreinoGeral)\n",
    "\n",
    "vect_tweetsTesteGeral = vectorizerGeral.transform(tweetsParaTesteGeral) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTreino = len(dadosTreinoGeral)\n",
    "qtdTweetsTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTeste = len(dadosTesteGeral)\n",
    "qtdTweetsTeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTreinoGeral = vectorizerGeral.fit_transform(tweetsParaTreinoGeral) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classificadorMultinomialGeral = MultinomialNB()\n",
    "classificadorMultinomialGeral.fit(vect_tweetsTreinoGeral, classesParaTreinoGeral)  \n",
    "\n",
    "classificadorSVMGeral = svm.SVC(kernel='linear')\n",
    "classificadorSVMGeral.fit(vect_tweetsTreinoGeral, classesParaTreinoGeral)\n",
    "\n",
    "classificadorLRGeral = LogisticRegression(random_state=0).fit(vect_tweetsTreinoGeral, classesParaTreinoGeral)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTesteGeral = vectorizerGeral.transform(tweetsParaTesteGeral) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultNaiveGeral = classificadorMultinomialGeral.predict(vect_tweetsTesteGeral)\n",
    "resultSVMGeral = classificadorSVMGeral.predict(vect_tweetsTesteGeral)\n",
    "resultLRGeral = classificadorLRGeral.predict(vect_tweetsTesteGeral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: 35.33% \n",
      "SVM: 35.0% \n",
      "Regressao Logistica: 36.67% \n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(classesParaTesteGeral, resultNaiveGeral) * 100\n",
    "print(\"Naive: {}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTesteGeral, resultSVMGeral) * 100\n",
    "print(\"SVM: {}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTesteGeral, resultLRGeral) * 100\n",
    "print(\"Regressao Logistica: {}{} \".format(acc3.round(2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = ['Netflix um cu de streaming']\n",
    "#vect_tweets = vectorizer.transform(test) \n",
    "#ve = ada.predict(vect_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito  0.0  1.0  2.0  All\n",
      "Real                       \n",
      "0         46   16   38  100\n",
      "1         14   38    7   59\n",
      "2         96   23   22  141\n",
      "All      156   77   67  300\n",
      "Predito  0.0  1.0  2.0  All\n",
      "Real                       \n",
      "0         53   11   36  100\n",
      "1         21   24   14   59\n",
      "2        101   12   28  141\n",
      "All      175   47   78  300\n",
      "Predito  0.0  1.0  2.0  All\n",
      "Real                       \n",
      "0         57   12   31  100\n",
      "1         18   32    9   59\n",
      "2        111    9   21  141\n",
      "All      186   53   61  300\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classesParaTesteGeral, resultNaiveGeral, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteGeral, resultSVMGeral, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTesteGeral, resultLRGeral, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteGeral, resultForest, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "#print (pd.crosstab(classesParaTesteGeral, resultada, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.46      0.36       100\n",
      "           1       0.49      0.64      0.56        59\n",
      "           2       0.33      0.16      0.21       141\n",
      "\n",
      "    accuracy                           0.35       300\n",
      "   macro avg       0.37      0.42      0.38       300\n",
      "weighted avg       0.35      0.35      0.33       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.53      0.39       100\n",
      "           1       0.51      0.41      0.45        59\n",
      "           2       0.36      0.20      0.26       141\n",
      "\n",
      "    accuracy                           0.35       300\n",
      "   macro avg       0.39      0.38      0.36       300\n",
      "weighted avg       0.37      0.35      0.34       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.57      0.40       100\n",
      "           1       0.60      0.54      0.57        59\n",
      "           2       0.34      0.15      0.21       141\n",
      "\n",
      "    accuracy                           0.37       300\n",
      "   macro avg       0.42      0.42      0.39       300\n",
      "weighted avg       0.38      0.37      0.34       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classesParaTesteGeral, resultNaiveGeral, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteGeral, resultSVMGeral, labels = [0,1,2]))\n",
    "print(classification_report(classesParaTesteGeral, resultLRGeral, labels = [0,1,2]))\n",
    "#print(classification_report(classesParaTesteGeral, resultForest, labels = [0,1,2]))\n",
    "#print(classification_report(classesParaTesteGeral, resultada, labels = [0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dadosTreino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-e5b9b93d8c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# validacao crosss todos os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdadosgeral\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdadosTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdadosTeste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## cross\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dadosTreino' is not defined"
     ]
    }
   ],
   "source": [
    "# validacao crosss todos os dados\n",
    "#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\n",
    "dadosgeral  = pd.concat([dadosTreino, dadosTeste])\n",
    "\n",
    "## cross\n",
    "#scores = cross_val_score(classificadorLRGeral,vect_tweetsTeste, classesParaTeste, cv=5, scoring='accuracy')\n",
    "tweetsParaTreino = dadosgeral['full_text'].values\n",
    "classesParaTreino = dadosgeral['SentimentoFinal'].values\n",
    "tweetsParaTeste = dadosgeral['full_text'].values\n",
    "classesParaTeste = dadosgeral['SentimentoFinal'].values\n",
    "\n",
    "#vect_tweetsTesteTreino = vectorizer.transform(tweetsParaTreino) \n",
    "scoresSVM = cross_val_score(classificadorMultinomialGeral,vect_tweetsTreinoGeral, classesParaTreinoGeral, cv=5, scoring='accuracy')\n",
    "print(\"Multinomial: \", scoresSVM.mean() )\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorSVMGeral,vect_tweetsTreinoGeral, classesParaTreinoGeral, cv=5, scoring='accuracy')\n",
    "print(\"SVM: \", scoresSVM.mean() )\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorLRGeral,vect_tweetsTreinoGeral, classesParaTreinoGeral, cv=5, scoring='accuracy')\n",
    "print(\"LOGISTICO: \", scoresSVM.mean())\n",
    "\n",
    "#scoresSVM = cross_val_score(resultCombinado,vect_tweetsTesteTreino, classesParaTreino, cv=5, scoring='accuracy')\n",
    "#print(\"Combinado: \", scoresSVM.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "#Positivo e negativo binario\n",
    "dadosPositivoNegativoTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] != 0]\n",
    "dadosPositivoNegativoTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] != 0]\n",
    "print(len(dadosPositivoNegativoTreino))\n",
    "print(len(dadosPositivoNegativoTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar os textos dos tweets de treinamento e teste e seus respectivos sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsParaTreinoPositivoNegativo = dadosPositivoNegativoTreino['full_text'].values\n",
    "classesParaTreinoPositivoNegativo = dadosPositivoNegativoTreino['SentimentoFinal'].values\n",
    "tweetsParaTestePositivoNegativo = dadosPositivoNegativoTeste['full_text'].values\n",
    "classesParaTestePositivoNegativo = dadosPositivoNegativoTeste['SentimentoFinal'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos a técnica Holdout, separando os dados em 70% para treinamento e 30% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTreino = len(dadosPositivoNegativoTreino)\n",
    "qtdTweetsTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTeste = len(dadosPositivoNegativoTeste)\n",
    "qtdTweetsTeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, instanciamos o vetorizador dos tweets. Ele é responsável pela transformação dos dados textuais em um formato que o algoritmo entenda. É utilizada a técnica Bag Of Words, aonde as palavras viram colunas em uma tabela e cada tweet terá uma representação de 0's e 1's. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, vetorizamos os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 2781)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizerPositivoNegativo = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)\n",
    "#vectorizer = TfidfVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)\n",
    "\n",
    "vect_tweetsTreinoPositivoNegativo = vectorizerPositivoNegativo.fit_transform(tweetsParaTreinoPositivoNegativo) \n",
    "vect_tweetsTestePositivoNegativo = vectorizerPositivoNegativo.transform(tweetsParaTestePositivoNegativo)\n",
    "vect_tweetsTreinoPositivoNegativo.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, faremos o treinamento do algoritmo. Utilizamos o algoritmo Multinomial Naive Bayes, o SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classificadorMultinomialPositivoNegativo = MultinomialNB()\n",
    "classificadorMultinomialPositivoNegativo.fit(vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo)  \n",
    "\n",
    "classificadorSVMPositivoNegativo = svm.SVC(kernel='linear')\n",
    "classificadorSVMPositivoNegativo.fit(vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo)\n",
    "\n",
    "classificadorLRPositivoNegativo = LogisticRegression(random_state=0).fit(vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já tendo o algoritmo sido treinado, faremos a vetorização dos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, fazemos a predição dos dados de teste por parte do algoritmo já treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPositivoNegativo = classificadorMultinomialPositivoNegativo.predict(vect_tweetsTestePositivoNegativo)\n",
    "resultSVMPositivoNegativo = classificadorSVMPositivoNegativo.predict(vect_tweetsTestePositivoNegativo)\n",
    "resultLRPositivoNegativo = classificadorLRPositivoNegativo.predict(vect_tweetsTestePositivoNegativo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: 73.3% \n",
      "SVM: 76.18% \n",
      "Regressao Logistica: 74.61% \n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(classesParaTestePositivoNegativo, resultPositivoNegativo) * 100\n",
    "print(\"Naive: {}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTestePositivoNegativo, resultSVMPositivoNegativo) * 100\n",
    "print(\"SVM: {}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTestePositivoNegativo, resultLRPositivoNegativo) * 100\n",
    "print(\"Regressao Logistica: {}{} \".format(acc3.round(2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial:  0.7159090909090908\n",
      "SVM:  0.7\n",
      "LOGISTICO:  0.7272727272727272\n"
     ]
    }
   ],
   "source": [
    "# validacao crosss todos os dados\n",
    "#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\n",
    "#vect_tweetsTestePositivoNegativo = vectorizer.transform(tweetsParaTreino) \n",
    "scoresSVM = cross_val_score(classificadorMultinomialPositivoNegativo,vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo, cv=5, scoring='accuracy')\n",
    "print(\"Multinomial: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorSVMPositivoNegativo,vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo, cv=5, scoring='accuracy')\n",
    "print(\"SVM: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorLRPositivoNegativo,vect_tweetsTreinoPositivoNegativo, classesParaTreinoPositivoNegativo, cv=5, scoring='accuracy')\n",
    "print(\"LOGISTICO: \", scoresSVM.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    1    2  All\n",
      "Real                  \n",
      "1        151   49  200\n",
      "2         53  129  182\n",
      "All      204  178  382\n",
      "Predito    1    2  All\n",
      "Real                  \n",
      "1        153   47  200\n",
      "2         44  138  182\n",
      "All      197  185  382\n",
      "Predito    1    2  All\n",
      "Real                  \n",
      "1        150   50  200\n",
      "2         47  135  182\n",
      "All      197  185  382\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classesParaTestePositivoNegativo, resultPositivoNegativo, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTestePositivoNegativo, resultSVMPositivoNegativo, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTestePositivoNegativo, resultLRPositivoNegativo, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       200\n",
      "           2       0.72      0.71      0.72       182\n",
      "\n",
      "    accuracy                           0.73       382\n",
      "   macro avg       0.73      0.73      0.73       382\n",
      "weighted avg       0.73      0.73      0.73       382\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.77       200\n",
      "           2       0.75      0.76      0.75       182\n",
      "\n",
      "    accuracy                           0.76       382\n",
      "   macro avg       0.76      0.76      0.76       382\n",
      "weighted avg       0.76      0.76      0.76       382\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.76       200\n",
      "           2       0.73      0.74      0.74       182\n",
      "\n",
      "    accuracy                           0.75       382\n",
      "   macro avg       0.75      0.75      0.75       382\n",
      "weighted avg       0.75      0.75      0.75       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classesParaTestePositivoNegativo, resultPositivoNegativo, labels = [1,2]))\n",
    "print(classification_report(classesParaTestePositivoNegativo, resultSVMPositivoNegativo, labels = [1,2]))\n",
    "print(classification_report(classesParaTestePositivoNegativo, resultLRPositivoNegativo, labels = [1,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "#Positivo e neutro binario\n",
    "dadosPositivoNeutroTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] != 2]\n",
    "dadosPositivoNeutroTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] != 2]\n",
    "print(len(dadosPositivoNeutroTreino))\n",
    "print(len(dadosPositivoNeutroTeste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "      <th>created_at</th>\n",
       "      <th>level_0</th>\n",
       "      <th>Sentimento1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>procur defeit tim gremi falh misera</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-23 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td></td>\n",
       "      <td>!enhorabuen la y tod la aficion brasilen la me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-07 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265</td>\n",
       "      <td>125</td>\n",
       "      <td>marvel lanc nft ofic sup heroil nest final seman</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu Aug 05 21:18:17 +0000 2021</td>\n",
       "      <td>125</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>glob olimpi despe melhor nosgalva final futebo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-07 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>sao benefici vem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Aug 10 00:35:53 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 index                                          full_text  \\\n",
       "0          33                      procur defeit tim gremi falh misera   \n",
       "2         129        !enhorabuen la y tod la aficion brasilen la me...   \n",
       "3         265   125   marvel lanc nft ofic sup heroil nest final seman   \n",
       "4          23        glob olimpi despe melhor nosgalva final futebo...   \n",
       "5         142     2                                   sao benefici vem   \n",
       "\n",
       "   Sentimento1 Sentimento2  SentimentoFinal                      created_at  \\\n",
       "0            1           1                1             2020-07-23 00:00:00   \n",
       "2            1           0                0             2021-08-07 00:00:00   \n",
       "3            0           1                1  Thu Aug 05 21:18:17 +0000 2021   \n",
       "4            0           1                1             2021-08-07 00:00:00   \n",
       "5            0           0                0  Tue Aug 10 00:35:53 +0000 2021   \n",
       "\n",
       "  level_0 Sentimento1.1  \n",
       "0                        \n",
       "2                        \n",
       "3     125                \n",
       "4                        \n",
       "5                        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosPositivoNeutroTreino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "      <th>created_at</th>\n",
       "      <th>level_0</th>\n",
       "      <th>Sentimento1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291</td>\n",
       "      <td>151</td>\n",
       "      <td>salari min pod ter mai reajust ano alt inflaca</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Aug 09 13:15:00 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225</td>\n",
       "      <td>85</td>\n",
       "      <td>presid congress acompanh ministr flav arrud ci...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Aug 09 19:58:13 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174</td>\n",
       "      <td></td>\n",
       "      <td>segund tempor amo seri</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120</td>\n",
       "      <td></td>\n",
       "      <td>nao to super final</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-23 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>274</td>\n",
       "      <td>134</td>\n",
       "      <td>agend consult agor oncolog brasil unidad macap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Aug 09 18:01:18 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 index                                          full_text  \\\n",
       "2         291   151     salari min pod ter mai reajust ano alt inflaca   \n",
       "3         225    85  presid congress acompanh ministr flav arrud ci...   \n",
       "4         174                                   segund tempor amo seri   \n",
       "6         120                                       nao to super final   \n",
       "9         274   134     agend consult agor oncolog brasil unidad macap   \n",
       "\n",
       "   Sentimento1 Sentimento2  SentimentoFinal                      created_at  \\\n",
       "2            1           1                1  Mon Aug 09 13:15:00 +0000 2021   \n",
       "3            0           1                1  Mon Aug 09 19:58:13 +0000 2021   \n",
       "4            1                            1                                   \n",
       "6            1           0                1             2019-11-23 00:00:00   \n",
       "9            0           0                0  Mon Aug 09 18:01:18 +0000 2021   \n",
       "\n",
       "  level_0 Sentimento1.1  \n",
       "2                        \n",
       "3                        \n",
       "4                     1  \n",
       "6                        \n",
       "9                        "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosPositivoNeutroTeste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsParaTreinoPositivoNeutro = dadosPositivoNeutroTreino['full_text'].values\n",
    "classesParaTreinoPositivoNeutro = dadosPositivoNeutroTreino['SentimentoFinal'].values\n",
    "tweetsParaTestePositivoNeutro = dadosPositivoNeutroTeste['full_text'].values\n",
    "classesParaTestePositivoNeutro = dadosPositivoNeutroTeste['SentimentoFinal'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTreino = len(dadosPositivoNeutroTreino)\n",
    "qtdTweetsTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTeste = len(dadosPositivoNeutroTeste)\n",
    "qtdTweetsTeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 2834)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizerPositivoNeutro = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)\n",
    "vect_tweetsTreinoPositivoNeutro = vectorizerPositivoNeutro.fit_transform(tweetsParaTreinoPositivoNeutro) \n",
    "vect_tweetsTreinoPositivoNeutro.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificadorMultinomialPositivoNeutro = MultinomialNB()\n",
    "classificadorMultinomialPositivoNeutro.fit(vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro)  \n",
    "\n",
    "classificadorSVMPositivoNeutro = svm.SVC(kernel='linear')\n",
    "classificadorSVMPositivoNeutro.fit(vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro)\n",
    "\n",
    "classificadorLRPositivoNeutro = LogisticRegression(random_state=0).fit(vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTestePositivoNeutro = vectorizerPositivoNeutro.transform(tweetsParaTestePositivoNeutro) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPositivoNeutro = classificadorMultinomialPositivoNeutro.predict(vect_tweetsTestePositivoNeutro)\n",
    "resultSVMPositivoNeutro = classificadorSVMPositivoNeutro.predict(vect_tweetsTestePositivoNeutro)\n",
    "resultLRPositivoNeutro = classificadorLRPositivoNeutro.predict(vect_tweetsTestePositivoNeutro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: 70.23% \n",
      "SVM: 68.15% \n",
      "Regressao Logistica: 69.45% \n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(classesParaTestePositivoNeutro, resultPositivoNeutro) * 100\n",
    "print(\"Naive: {}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTestePositivoNeutro, resultSVMPositivoNeutro) * 100\n",
    "print(\"SVM: {}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTestePositivoNeutro, resultLRPositivoNeutro) * 100\n",
    "print(\"Regressao Logistica: {}{} \".format(acc3.round(2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1c8c3ea2abe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# validacao crosss todos os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvect_tweetsTesteTreino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetsParaTreino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscoresSVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificadorMultinomialPositivoNeutro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvect_tweetsTreinoPositivoNeutro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassesParaTreinoPositivoNeutro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Multinomial: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoresSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# validacao crosss todos os dados\n",
    "#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\n",
    "vect_tweetsTesteTreino = vectorizer.transform(tweetsParaTreino) \n",
    "scoresSVM = cross_val_score(classificadorMultinomialPositivoNeutro,vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro, cv=5, scoring='accuracy')\n",
    "print(\"Multinomial: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorSVMPositivoNeutro,vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro, cv=5, scoring='accuracy')\n",
    "print(\"SVM: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorLRPositivoNeutro,vect_tweetsTreinoPositivoNeutro, classesParaTreinoPositivoNeutro, cv=5, scoring='accuracy')\n",
    "print(\"LOGISTICO: \", scoresSVM.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    0    1  All\n",
      "Real                  \n",
      "0        114   69  183\n",
      "1         45  155  200\n",
      "All      159  224  383\n",
      "Predito    0    1  All\n",
      "Real                  \n",
      "0        122   61  183\n",
      "1         61  139  200\n",
      "All      183  200  383\n",
      "Predito    0    1  All\n",
      "Real                  \n",
      "0        129   54  183\n",
      "1         63  137  200\n",
      "All      192  191  383\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classesParaTestePositivoNeutro, resultPositivoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTestePositivoNeutro, resultSVMPositivoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTestePositivoNeutro, resultLRPositivoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       183\n",
      "           1       0.69      0.78      0.73       200\n",
      "\n",
      "    accuracy                           0.70       383\n",
      "   macro avg       0.70      0.70      0.70       383\n",
      "weighted avg       0.70      0.70      0.70       383\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       183\n",
      "           1       0.69      0.69      0.69       200\n",
      "\n",
      "    accuracy                           0.68       383\n",
      "   macro avg       0.68      0.68      0.68       383\n",
      "weighted avg       0.68      0.68      0.68       383\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69       183\n",
      "           1       0.72      0.69      0.70       200\n",
      "\n",
      "    accuracy                           0.69       383\n",
      "   macro avg       0.69      0.69      0.69       383\n",
      "weighted avg       0.70      0.69      0.69       383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classesParaTestePositivoNeutro, resultPositivoNeutro, labels = [0,1]))\n",
    "print(classification_report(classesParaTestePositivoNeutro, resultSVMPositivoNeutro, labels = [0,1]))\n",
    "print(classification_report(classesParaTestePositivoNeutro, resultLRPositivoNeutro, labels = [0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "#negativo neutro\n",
    "dadosNegativoNeutroTreino = dadosTreinoGeral[dadosTreinoGeral['SentimentoFinal'] != 1]\n",
    "dadosNegativoNeutroTeste = dadosTesteGeral[dadosTesteGeral['SentimentoFinal'] != 1]\n",
    "print(len(dadosNegativoNeutroTreino))\n",
    "print(len(dadosNegativoNeutroTeste))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "      <th>created_at</th>\n",
       "      <th>level_0</th>\n",
       "      <th>Sentimento1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>diret nao ganh titulosess diret nao ganh grena...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-07-23 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td></td>\n",
       "      <td>!enhorabuen la y tod la aficion brasilen la me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-07 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>sao benefici vem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Aug 10 00:35:53 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145</td>\n",
       "      <td></td>\n",
       "      <td>raf manu prepar entr aaaaaaaaa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-28 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>n aguent perd gren</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-07-23 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 index                                          full_text  \\\n",
       "1           16        diret nao ganh titulosess diret nao ganh grena...   \n",
       "2          129        !enhorabuen la y tod la aficion brasilen la me...   \n",
       "5          142     2                                   sao benefici vem   \n",
       "7          145                           raf manu prepar entr aaaaaaaaa   \n",
       "10          60                                       n aguent perd gren   \n",
       "\n",
       "    Sentimento1 Sentimento2  SentimentoFinal                      created_at  \\\n",
       "1             2           2                2             2020-07-23 00:00:00   \n",
       "2             1           0                0             2021-08-07 00:00:00   \n",
       "5             0           0                0  Tue Aug 10 00:35:53 +0000 2021   \n",
       "7             0           1                0             2020-04-28 00:00:00   \n",
       "10            2           2                2             2020-07-23 00:00:00   \n",
       "\n",
       "   level_0 Sentimento1.1  \n",
       "1                         \n",
       "2                         \n",
       "5                         \n",
       "7                         \n",
       "10                        "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosNegativoNeutroTreino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentimento1</th>\n",
       "      <th>Sentimento2</th>\n",
       "      <th>SentimentoFinal</th>\n",
       "      <th>created_at</th>\n",
       "      <th>level_0</th>\n",
       "      <th>Sentimento1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213</td>\n",
       "      <td></td>\n",
       "      <td>continu sag</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td></td>\n",
       "      <td>zach snyd estil mei duvid opinia army of the d...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td></td>\n",
       "      <td>ui gent vitor fod viu vitor vo ta vend tund at...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-07-23 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>269</td>\n",
       "      <td>129</td>\n",
       "      <td>mov afirm reform eleitor racist reduz mandat n...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Mon Aug 09 17:37:56 +0000 2021</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>291</td>\n",
       "      <td></td>\n",
       "      <td>secret geral paicip delegaca glob summit event...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 index                                          full_text  \\\n",
       "0         213                                              continu sag   \n",
       "1         251        zach snyd estil mei duvid opinia army of the d...   \n",
       "5         102        ui gent vitor fod viu vitor vo ta vend tund at...   \n",
       "7         269   129  mov afirm reform eleitor racist reduz mandat n...   \n",
       "8         291        secret geral paicip delegaca glob summit event...   \n",
       "\n",
       "   Sentimento1 Sentimento2  SentimentoFinal                      created_at  \\\n",
       "0            2                            2                                   \n",
       "1            2                            2                                   \n",
       "5            2           2                2             2020-07-23 00:00:00   \n",
       "7            2           2                2  Mon Aug 09 17:37:56 +0000 2021   \n",
       "8            2           2                2                                   \n",
       "\n",
       "  level_0 Sentimento1.1  \n",
       "0                     2  \n",
       "1                     1  \n",
       "5                        \n",
       "7                        \n",
       "8                        "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosNegativoNeutroTeste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsParaTreino = dadosNegativoNeutroTreino['full_text'].values\n",
    "classesParaTreino = dadosNegativoNeutroTreino['SentimentoFinal'].values\n",
    "tweetsParaTeste = dadosNegativoNeutroTeste['full_text'].values\n",
    "classesParaTeste = dadosNegativoNeutroTeste['SentimentoFinal'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTreino = len(dadosNegativoNeutroTreino)\n",
    "qtdTweetsTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTweetsTeste = len(dadosNegativoNeutroTeste)\n",
    "qtdTweetsTeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o objeto que faz a vetorização dos dados de texto:\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "vectorizerNegativoNeutro = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTreino = vectorizerNegativoNeutro.fit_transform(tweetsParaTreino) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tweetsTeste = vectorizerNegativoNeutro.transform(tweetsParaTeste) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificadorMultinomialNegativoNeutro = MultinomialNB()\n",
    "classificadorMultinomialNegativoNeutro.fit(vect_tweetsTreino, classesParaTreino)  \n",
    "\n",
    "classificadorSVMNegativoNeutro = svm.SVC(kernel='linear')\n",
    "classificadorSVMNegativoNeutro.fit(vect_tweetsTreino, classesParaTreino)\n",
    "\n",
    "classificadorLRNegativoNeutro = LogisticRegression(random_state=0).fit(vect_tweetsTreino, classesParaTreino)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultNegativoNeutro = classificadorMultinomialNegativoNeutro.predict(vect_tweetsTeste)\n",
    "resultSVMNegativoNeutro = classificadorSVMNegativoNeutro.predict(vect_tweetsTeste)\n",
    "resultLRNegativoNeutro = classificadorLRNegativoNeutro.predict(vect_tweetsTeste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: 70.41% \n",
      "SVM: 70.96% \n",
      "Regressao Logistica: 70.14% \n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(classesParaTeste, resultNegativoNeutro) * 100\n",
    "print(\"Naive: {}{} \".format(acc.round(2), \"%\"))\n",
    "\n",
    "acc2 = accuracy_score(classesParaTeste, resultSVMNegativoNeutro) * 100\n",
    "print(\"SVM: {}{} \".format(acc2.round(2), \"%\"))\n",
    "\n",
    "acc3 = accuracy_score(classesParaTeste, resultLRNegativoNeutro) * 100\n",
    "print(\"Regressao Logistica: {}{} \".format(acc3.round(2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-00d9c056407f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# validacao crosss todos os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvect_tweetsTesteTreino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetsParaTreino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscoresSVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificadorMultinomialNegativoNeutro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvect_tweetsTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassesParaTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Multinomial: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoresSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# validacao crosss todos os dados\n",
    "#https://minerandodados.com.br/validacao-cruzada-aprenda-de-forma-simples-como-usar-essa-tecnica/\n",
    "vect_tweetsTesteTreino = vectorizer.transform(tweetsParaTreino) \n",
    "scoresSVM = cross_val_score(classificadorMultinomialNegativoNeutro,vect_tweetsTreino, classesParaTreino, cv=5, scoring='accuracy')\n",
    "print(\"Multinomial: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorSVMNegativoNeutro,vect_tweetsTreino, classesParaTreino, cv=5, scoring='accuracy')\n",
    "print(\"SVM: \", scoresSVM.mean())\n",
    "\n",
    "scoresSVM = cross_val_score(classificadorLRNegativoNeutro,vect_tweetsTreino, classesParaTreino, cv=5, scoring='accuracy')\n",
    "print(\"LOGISTICO: \", scoresSVM.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    0    2  All\n",
      "Real                  \n",
      "0        120   63  183\n",
      "2         45  137  182\n",
      "All      165  200  365\n",
      "Predito    0    2  All\n",
      "Real                  \n",
      "0        128   55  183\n",
      "2         51  131  182\n",
      "All      179  186  365\n",
      "Predito    0    2  All\n",
      "Real                  \n",
      "0        130   53  183\n",
      "2         56  126  182\n",
      "All      186  179  365\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resultCombinadoNegativoNeutro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b23912b2113c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassesParaTeste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultLRNegativoNeutro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Real'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassesParaTeste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultCombinadoNegativoNeutro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Real'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'resultCombinadoNegativoNeutro' is not defined"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classesParaTeste, resultNegativoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultSVMNegativoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultLRNegativoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "\n",
    "print (pd.crosstab(classesParaTeste, resultCombinadoNegativoNeutro, rownames=['Real'], colnames=['Predito'], margins=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       183\n",
      "           2       0.69      0.75      0.72       182\n",
      "\n",
      "    accuracy                           0.70       365\n",
      "   macro avg       0.71      0.70      0.70       365\n",
      "weighted avg       0.71      0.70      0.70       365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       183\n",
      "           2       0.70      0.72      0.71       182\n",
      "\n",
      "    accuracy                           0.71       365\n",
      "   macro avg       0.71      0.71      0.71       365\n",
      "weighted avg       0.71      0.71      0.71       365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70       183\n",
      "           2       0.70      0.69      0.70       182\n",
      "\n",
      "    accuracy                           0.70       365\n",
      "   macro avg       0.70      0.70      0.70       365\n",
      "weighted avg       0.70      0.70      0.70       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classesParaTeste, resultNegativoNeutro, labels = [0,2]))\n",
    "print(classification_report(classesParaTeste, resultSVMNegativoNeutro, labels = [0,2]))\n",
    "print(classification_report(classesParaTeste, resultLRNegativoNeutro, labels = [0,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble com os melhores de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterio de escolha do melhor algoritmo por ser ensemble nao podem ser repetidos caso sejam pouca\n",
    "#diferença ou nenhuma se dara nos resultados criterio de escolha\n",
    "# melhor f1-score por ser a media entre precisao e recall, desempate caso de o mesmo algoritmo o 2 melhor\n",
    "# caso no segundo melhor f1-score ser igual usar a acuracia\n",
    "# seguindo esta ordem temos negativo neutro SVM, positivo neutro Naive e positivo negativo logistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosTeste = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/dados_processados/dados_separados_thiago_gustavo/TweetsTreino30OversimplePreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "#dadosTeste = pd.read_excel('/Users/gustavoduarte/Desktop/TCC-analise-sentimentos-main/dados_processados/dados_separados_thiago_gustavo/TweetsTreino30OversimpleTesteIndividualPreProcessados.xlsx', engine='openpyxl').fillna(' ')\n",
    "\n",
    "#tweetsParaTreino = dadosTreinoGeral['full_text'].values\n",
    "#classesParaTreino = dadosTreinoGeral['SentimentoFinal'].values\n",
    "tweetsParaTeste = dadosTeste['full_text'].values\n",
    "classesParaTeste = dadosTeste['SentimentoFinal'].values\n",
    "#vect_tweetsTeste = vectorizer.transform(tweetsParaTeste)\n",
    "#vect_tweetsTreino = vectorizer.fit_transform(tweetsParaTreino) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seri boaaa'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsParaTeste[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = [tweetsParaTeste[6]]\n",
    "#vetorizacao para cada classe\n",
    "#positivo negativo\n",
    "vect_positivoNegativo = vectorizerPositivoNegativo.transform(teste) \n",
    "#negativo neutro\n",
    "vect_negativoNeutro = vectorizerNegativoNeutro.transform(teste) \n",
    "#positivo neutro\n",
    "vect_positivoNeutro = vectorizerPositivoNeutro.transform(teste) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = classificadorLRPositivoNegativo.predict(vect_positivoNegativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "re2 = classificadorMultinomialPositivoNeutro.predict(vect_positivoNeutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "re3 = classificadorSVMNegativoNeutro.predict(vect_negativoNeutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicts(text):\n",
    "    vect_positivoNegativo = vectorizerPositivoNegativo.transform(text) \n",
    "    #negativo neutro\n",
    "    vect_negativoNeutro = vectorizerNegativoNeutro.transform(text) \n",
    "    #positivo neutro\n",
    "    vect_positivoNeutro = vectorizerPositivoNeutro.transform(text)\n",
    "    rePositivoNegativo = classificadorLRPositivoNegativo.predict(vect_positivoNegativo)\n",
    "    rePositivoNeutro = classificadorMultinomialPositivoNeutro.predict(vect_positivoNeutro)\n",
    "    reNegativoNeutro = classificadorSVMNegativoNeutro.predict(vect_negativoNeutro)\n",
    "    resultFinal = []\n",
    "    if(rePositivoNeutro == 0 and reNegativoNeutro == 0):\n",
    "        resultFinal.append(0)\n",
    "    elif(rePositivoNeutro == 1 and rePositivoNegativo == 1):\n",
    "         resultFinal.append(1)\n",
    "    elif(reNegativoNeutro == 2 and  rePositivoNegativo == 2):\n",
    "         resultFinal.append(2)\n",
    "    else:\n",
    "        resultFinal.append(0)\n",
    "    return resultFinal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsDataset(dataset):\n",
    "    resultFinal = []\n",
    "    for index in range(len(dataset)):\n",
    "        text = [dataset[index]]\n",
    "        vect_positivoNegativo = vectorizerPositivoNegativo.transform(text) \n",
    "        #negativo neutro\n",
    "        vect_negativoNeutro = vectorizerNegativoNeutro.transform(text) \n",
    "        #positivo neutro\n",
    "        vect_positivoNeutro = vectorizerPositivoNeutro.transform(text)\n",
    "        rePositivoNegativo = classificadorLRPositivoNegativo.predict(vect_positivoNegativo)\n",
    "        rePositivoNeutro = classificadorMultinomialPositivoNeutro.predict(vect_positivoNeutro)\n",
    "        reNegativoNeutro = classificadorSVMNegativoNeutro.predict(vect_negativoNeutro)\n",
    "        if(rePositivoNeutro == 0 and reNegativoNeutro == 0):\n",
    "            resultFinal.append(0)\n",
    "        elif(rePositivoNeutro == 1 and rePositivoNegativo == 1):\n",
    "             resultFinal.append(1)\n",
    "        elif(reNegativoNeutro == 2 and  rePositivoNegativo == 2):\n",
    "            resultFinal.append(2)\n",
    "        else:\n",
    "            resultFinal.append(0)\n",
    "    return resultFinal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "text_example = [\"Netflix ultimamante anda horrivel\"]\n",
    "results = predicts(text_example)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsNossoAlgoritmo = predictsDataset(tweetsParaTeste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combinado: 70.8% \n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(classesParaTeste, resultsNossoAlgoritmo) * 100\n",
    "print(\"combinado: {}{} \".format(acc.round(2), \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       189\n",
      "           1       0.67      0.77      0.72       188\n",
      "           2       0.75      0.72      0.73       188\n",
      "\n",
      "    accuracy                           0.71       565\n",
      "   macro avg       0.71      0.71      0.71       565\n",
      "weighted avg       0.71      0.71      0.71       565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classesParaTeste, resultsNossoAlgoritmo, labels = [0,1,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classificadorSVMNegativoNeutro, open('classificadorSVMNegativoNeutro.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroku_url = \"http://127.0.0.1:5000/sentimental\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "data = {'full_text': \"Netflix esta lancando as piores series ultimamente que horror\"\n",
    "             , 'created_at': \"2018/04/03\"}\n",
    "data = json.dumps(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n"
     ]
    }
   ],
   "source": [
    "send_request = requests.post(heroku_url, data)\n",
    "print(send_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cdd67cbe76c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "print(send_request.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6b0f0ae176c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "response = send_request.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-46eb41a73cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response['results']['results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('amor-de-mae-video.json', \"r\")\n",
    " \n",
    "# Reading from file\n",
    "data = json.loads(f.read())\n",
    "#data = data[0:400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': '2021-04-10 02:18:59', 'username': 'neisa', 'retweets': 6356, 'favorites': 0, 'text': 'RT @drraphaelpedra: Sinto falta do Casseta &amp; Planeta pois só eles fariam uma paródia de Amor de Mãe que chamaria o chay suede de Chay Suado…', 'id': 1380706849813630983}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "data1 = json.dumps(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "send_request = requests.post(heroku_url, data1)\n",
    "print(send_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(data)):\n",
    "    datate = data[index]\n",
    "    datate_request = json.dumps(datate)\n",
    "    send_request = requests.post(heroku_url, datate_request)\n",
    "    response = send_request.json()\n",
    "    sentimental = response['results']['results']\n",
    "    if sentimental == 1:\n",
    "        datate['emotion'] = 'positivo'\n",
    "    if sentimental == 0:\n",
    "        datate['emotion'] = 'neutro'\n",
    "    if sentimental == 2:\n",
    "        datate['emotion'] = 'negativo'\n",
    "    data[index] = datate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('demo_test_amor_de_mae.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
